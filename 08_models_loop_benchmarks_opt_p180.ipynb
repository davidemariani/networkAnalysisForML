{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models loop automation - Pastdue180 tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses as inputs the outputs from the pipeline ('05_preproc_pipeline_1.ipynb' notebook) and performs model assessment of performances and general exploration for the transaction credit events prediction \"is_pastdue180\".  \n",
    "All the experiments produce useful data for visualizing results and can be tracked on MLflow.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\thesis_mlflow\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from scripts_ml.models_utils import *\n",
    "from scripts_viz.visualization_utils import *\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from bokeh.io import show, output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear model Stochastic Gradient Descent with semi-optimized hyperparameters using random search\n",
    "sgd_rs_1 = SGDClassifier(random_state=42, max_iter=350, loss='log', learning_rate='optimal', eta0=0.001, tol=0.0001) #from benchmark_imp_shuffle_tuning\n",
    "sgd_rs_2 = SGDClassifier(random_state=42, max_iter=200, loss='log', learning_rate='constant', eta0=0.001, tol=0.0001) #from benchmark_imp_time_tuning\n",
    "sgd_rs_3 = SGDClassifier(random_state=42, max_iter=180, loss='log', learning_rate='adaptive', eta0=0.01, tol=0.0001) #from benchmark_p90_shuffle_tuning\n",
    "sgd_rs_4 = SGDClassifier(random_state=42, max_iter=320, loss='log', learning_rate='constant', eta0=0.01, tol=0.0001) #from benchmark_p90_time_tuning\n",
    "sgd_rs_5 = SGDClassifier(random_state=42, max_iter=320, loss='log', learning_rate='adaptive', eta0=0.01, tol=0.0001) #from both benchmark_p180_shuffle_tuning and benchmark_p180_time_tuning\n",
    "\n",
    "sgd_models = [sgd_rs_1, sgd_rs_2, sgd_rs_3, sgd_rs_4, sgd_rs_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest models parameters from randomized grid search\n",
    "\n",
    "#from benchmark_imp_shuffle_tuning\n",
    "rf_opt_1 = {'n_estimators': 350,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_leaf_nodes': 80,\n",
    " 'max_features': 15,\n",
    " 'max_depth': 80,\n",
    " 'bootstrap': True,\n",
    " 'random_state':42,\n",
    " 'class_weight':\"balanced\",\n",
    "  'n_jobs': 7}\n",
    "\n",
    "#from benchmark_imp_time_tuning\n",
    "rf_opt_2 = {'n_estimators': 180,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_leaf_nodes': 25,\n",
    " 'max_features': 10,\n",
    " 'max_depth': None,\n",
    " 'bootstrap': True,\n",
    " 'random_state':42,\n",
    " 'class_weight':\"balanced\",\n",
    "  'n_jobs': 7}\n",
    "\n",
    "#from benchmark_p90_shuffle_tuning\n",
    "rf_opt_3 = {'n_estimators': 280,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_leaf_nodes': 100,\n",
    " 'max_features': 15,\n",
    " 'max_depth': 280,\n",
    " 'bootstrap': True,\n",
    " 'random_state':42,\n",
    " 'class_weight':\"balanced\",\n",
    "  'n_jobs': 7}\n",
    "\n",
    "#from benchmark_p90_time_tuning\n",
    "rf_opt_4 = {'n_estimators': 300,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_leaf_nodes': 80,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': None,\n",
    " 'bootstrap': True,\n",
    " 'random_state':42,\n",
    " 'class_weight':\"balanced\",\n",
    "  'n_jobs': 7}\n",
    "\n",
    "#from benchmark_p180_shuffle_tuning\n",
    "rf_opt_5 = {'n_estimators': 250,\n",
    " 'min_samples_split': 15,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_leaf_nodes': 100,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 180,\n",
    " 'bootstrap': True,\n",
    " 'random_state':42,\n",
    " 'class_weight':\"balanced\",\n",
    "  'n_jobs': 7}\n",
    "\n",
    "#from benchmark_p180_time_tuning \n",
    "rf_opt_6 = {'n_estimators': 180,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_leaf_nodes': 80,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 80,\n",
    " 'bootstrap': True,\n",
    " 'random_state':42,\n",
    " 'class_weight':\"balanced\",\n",
    "  'n_jobs': 7}\n",
    "\n",
    "rf_parameters = [rf_opt_1, rf_opt_2, rf_opt_3, rf_opt_4, rf_opt_5, rf_opt_6]\n",
    "\n",
    "rf_models = [RandomForestClassifier(**params) for params in rf_parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = sgd_models+rf_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes_shuffle = ['shuffle_p180_']\n",
    "postfixes_shuffle = ['_19072_750']\n",
    "preproc_folder = \"benchmarks_shuffle\" #folder with the correct preprocessing data\n",
    "expname = preproc_folder+\"_opt_p180\" #experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = \"../data/preproc_traintest/\"+preproc_folder+'/'\n",
    "output_path = \"../data/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment in Shuffle Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Loop 1 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.772\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.9987  0.0013 ]\n",
      " [0.0648  0.00334]]\n",
      "AUC 0.781\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__SGDClassifier_190817_10186.pkl\n",
      "- Creating the new experiment 'benchmarks_shuffle_opt_p180',  the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 2 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.769\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.99898 0.00102]\n",
      " [0.06638 0.00176]]\n",
      "AUC 0.783\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__SGDClassifier_190817_101813.pkl\n",
      "- Activating existing experiment 'benchmarks_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 3 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.774\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.99898 0.00102]\n",
      " [0.06591 0.00222]]\n",
      "AUC 0.786\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__SGDClassifier_190817_101823.pkl\n",
      "- Activating existing experiment 'benchmarks_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 4 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.770\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.99889 0.00111]\n",
      " [0.06628 0.00185]]\n",
      "AUC 0.775\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__SGDClassifier_190817_101829.pkl\n",
      "- Activating existing experiment 'benchmarks_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 5 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.774\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.99898 0.00102]\n",
      " [0.06591 0.00222]]\n",
      "AUC 0.786\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__SGDClassifier_190817_101838.pkl\n",
      "- Activating existing experiment 'benchmarks_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 6 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.970\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.91833 0.08167]\n",
      " [0.00528 0.06285]]\n",
      "AUC 0.972\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__RandomForestClassifier_190817_102044.pkl\n",
      "- Activating existing experiment 'benchmarks_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 7 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.948\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.82294 0.17706]\n",
      " [0.00593 0.0622 ]]\n",
      "AUC 0.949\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__RandomForestClassifier_190817_102125.pkl\n",
      "- Activating existing experiment 'benchmarks_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 8 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.973\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.92788 0.07212]\n",
      " [0.00528 0.06285]]\n",
      "AUC 0.974\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__RandomForestClassifier_190817_10233.pkl\n",
      "- Activating existing experiment 'benchmarks_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 9 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.968\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.9111  0.0889 ]\n",
      " [0.00556 0.06258]]\n",
      "AUC 0.970\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__RandomForestClassifier_190817_102354.pkl\n",
      "- Activating existing experiment 'benchmarks_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 10 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.971\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.92268 0.07732]\n",
      " [0.00556 0.06258]]\n",
      "AUC 0.972\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__RandomForestClassifier_190817_102441.pkl\n",
      "- Activating existing experiment 'benchmarks_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 11 of 11 for credit event shuffle_p180_----\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_ and postfix _19072_750 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__traindata_19072_750.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_shuffle/shuffle_p180__testdata_19072_750.pkl\n",
      "- Training/Validation...\n",
      "AUC 0.968\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.911   0.089  ]\n",
      " [0.00538 0.06276]]\n",
      "AUC 0.970\n",
      "- Saving the model to ../data/models/benchmarks_shuffle_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_shuffle_opt_p180/shuffle_p180__RandomForestClassifier_190817_102519.pkl\n",
      "- Activating existing experiment 'benchmarks_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "Experiment done!\n"
     ]
    }
   ],
   "source": [
    "experiment_shuffle = models_loop(models, datafolder, prefixes_shuffle, postfixes_shuffle, mlf_tracking=True, save_model=True,\n",
    "                                experiment_name=expname, save_results_for_viz=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment in Time mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_folder = \"benchmarks_time\" #folder with the correct preprocessing data\n",
    "expname = preproc_folder+\"_opt_p180\" #experiment name\n",
    "datafolder = \"../data/preproc_traintest/\"+preproc_folder+'/'\n",
    "prefixes_time = ['time_2018-02-20_p180_']\n",
    "postfixes_time = ['_190710_745']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Loop 1 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.3604058169498856\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.6474719999999999\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.5859518889466087\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.597413278762567\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.5944818299477068\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.6130757613893784\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.8316966006734983\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.8629010468132411\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.8389488077679449\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.8708995023299406\n",
      "Validation AUC 0.626\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.96074 0.03926]\n",
      " [0.00336 0.00013]]\n",
      "AUC 0.720\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__SGDClassifier_190817_102525.pkl\n",
      "- Creating the new experiment 'benchmarks_time_opt_p180',  the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 2 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.3587259253919914\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.6356103999999999\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.5935232469536516\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.5844155482075846\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.6756798870643833\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.6116325087960757\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.8548727888661882\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.8666837790266798\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.834806979269092\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.8770576742835268\n",
      "Validation AUC 0.638\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.95919 0.04081]\n",
      " [0.00336 0.00013]]\n",
      "AUC 0.706\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__SGDClassifier_190817_102533.pkl\n",
      "- Activating existing experiment 'benchmarks_time_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 3 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.35563177471165863\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.6470696\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.5977479932455113\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.580374319027094\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.6620071422009655\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.6120917255303083\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.8455856574668457\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.8717306385869565\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.83711027122255\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.8817461574679111\n",
      "Validation AUC 0.636\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.96494 0.03506]\n",
      " [0.00336 0.00013]]\n",
      "AUC 0.718\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__SGDClassifier_190817_102541.pkl\n",
      "- Activating existing experiment 'benchmarks_time_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 4 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.3528352925393994\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.6434335999999999\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.6055388848967234\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.5845884051990923\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.6839558630120738\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.603966400865416\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.8448361319648447\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.873625864624506\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.8271084275647329\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.877412995744943\n",
      "Validation AUC 0.630\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.96997 0.03003]\n",
      " [0.00336 0.00013]]\n",
      "AUC 0.779\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__SGDClassifier_190817_102549.pkl\n",
      "- Activating existing experiment 'benchmarks_time_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 5 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.35563177471165863\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.6470696\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.5977479932455113\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.580374319027094\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.6620071422009655\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.6120917255303083\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.8455856574668457\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.8717306385869565\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.83711027122255\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.8817461574679111\n",
      "Validation AUC 0.636\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.96494 0.03506]\n",
      " [0.00336 0.00013]]\n",
      "AUC 0.718\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__SGDClassifier_190817_102557.pkl\n",
      "- Activating existing experiment 'benchmarks_time_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 6 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.5003547327624238\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.8074856\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.7057719479398937\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.8413800121557498\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.9281628542756108\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.8753393919595567\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.8957353610818958\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.9451002038043478\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.9303916748607015\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.8573543842048059\n",
      "Validation AUC 0.828\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.83869 0.16131]\n",
      " [0.00291 0.00058]]\n",
      "AUC 0.738\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__RandomForestClassifier_190817_102645.pkl\n",
      "- Activating existing experiment 'benchmarks_time_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 7 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.3235476479849644\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.8290852\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.7047693684195747\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.7963444928320109\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.9265837092233467\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.8759150864077202\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.8903630900330571\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.9395833976655138\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.8943097549983612\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.8654184212726448\n",
      "Validation AUC 0.814\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.76056 0.23944]\n",
      " [0.00213 0.00136]]\n",
      "AUC 0.656\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__RandomForestClassifier_190817_10274.pkl\n",
      "- Activating existing experiment 'benchmarks_time_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 8 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.516226604489989\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.8066784\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.7145883935625588\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.8337185442095696\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.9277849292815122\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.8799549887270994\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.8942766071478943\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.9440715322381423\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.9286120329400196\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.8596194210130291\n",
      "Validation AUC 0.832\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.84328 0.15672]\n",
      " [0.00297 0.00052]]\n",
      "AUC 0.769\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__RandomForestClassifier_190817_102745.pkl\n",
      "- Activating existing experiment 'benchmarks_time_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 9 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.35962693993436606\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.8285504000000001\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.767386234985239\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.8592818628407652\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.9370307189063666\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.885825063861919\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.9154392850762487\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.9483328958745059\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.9290441402409045\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.8796351299618497\n",
      "Validation AUC 0.789\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.83275 0.16725]\n",
      " [0.00252 0.00097]]\n",
      "AUC 0.728\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__RandomForestClassifier_190817_10288.pkl\n",
      "- Activating existing experiment 'benchmarks_time_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 10 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.3084806825819206\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.8243460000000001\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.7783788716736505\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.8644215703221274\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.9377714518947996\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.8843985465723421\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.917772485429251\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.9482692070158102\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.934126362258276\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.8758514514276663\n",
      "Validation AUC 0.803\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.84147 0.15853]\n",
      " [0.00278 0.00071]]\n",
      "AUC 0.751\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__RandomForestClassifier_190817_102827.pkl\n",
      "- Activating existing experiment 'benchmarks_time_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "----Loop 11 of 11 for credit event time_2018-02-20_p180_----\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_ and postfix _190710_745 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__traindata_190710_745.pkl\n",
      "testing files: ../data/preproc_traintest/benchmarks_time/time_2018-02-20_p180__testdata_190710_745.pkl\n",
      "- Training/Validation...\n",
      "Preparing fold 0 with 12079 train observations and 3000 test observations, starti=3079...\n",
      "Fold 0: train  on 12079 from index 0 to 12078, test on 3000 from 12079 to 15078\n",
      "Fold 0 AUC: 0.35710276437935784\n",
      "Preparing fold 1 with 12000 train observations and 3000 test observations, starti=6079...\n",
      "Fold 1: train  on 12000 from index 3079 to 15078, test on 3000 from 15079 to 18078\n",
      "Fold 1 AUC: 0.8325687999999999\n",
      "Preparing fold 2 with 12000 train observations and 3000 test observations, starti=9079...\n",
      "Fold 2: train  on 12000 from index 6079 to 18078, test on 3000 from 18079 to 21078\n",
      "Fold 2 AUC: 0.7539870245405429\n",
      "Preparing fold 3 with 12000 train observations and 3000 test observations, starti=12079...\n",
      "Fold 3: train  on 12000 from index 9079 to 21078, test on 3000 from 21079 to 24078\n",
      "Fold 3 AUC: 0.8556672001070599\n",
      "Preparing fold 4 with 12000 train observations and 3000 test observations, starti=15079...\n",
      "Fold 4: train  on 12000 from index 12079 to 24078, test on 3000 from 24079 to 27078\n",
      "Fold 4 AUC: 0.9378034301635311\n",
      "Preparing fold 5 with 12000 train observations and 3000 test observations, starti=18079...\n",
      "Fold 5: train  on 12000 from index 15079 to 27078, test on 3000 from 27079 to 30078\n",
      "Fold 5 AUC: 0.8824204336719667\n",
      "Preparing fold 6 with 12000 train observations and 3000 test observations, starti=21079...\n",
      "Fold 6: train  on 12000 from index 18079 to 30078, test on 3000 from 30079 to 33078\n",
      "Fold 6 AUC: 0.918723496281252\n",
      "Preparing fold 7 with 12000 train observations and 3000 test observations, starti=24079...\n",
      "Fold 7: train  on 12000 from index 21079 to 33078, test on 3000 from 33079 to 36078\n",
      "Fold 7 AUC: 0.9478619843132411\n",
      "Preparing fold 8 with 12000 train observations and 3000 test observations, starti=27079...\n",
      "Fold 8: train  on 12000 from index 24079 to 36078, test on 3000 from 36079 to 39078\n",
      "Fold 8 AUC: 0.9282573848738118\n",
      "Preparing fold 9 with 12000 train observations and 3000 test observations, starti=30079...\n",
      "Fold 9: train  on 12000 from index 27079 to 39078, test on 3000 from 39079 to 42078\n",
      "Fold 9 AUC: 0.8758784030555447\n",
      "Validation AUC 0.786\n",
      "- Training for test...\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.83508 0.16492]\n",
      " [0.00252 0.00097]]\n",
      "AUC 0.731\n",
      "- Saving the model to ../data/models/benchmarks_time_opt_p180/...\n",
      "- Saving model to ../data/models/benchmarks_time_opt_p180/time_2018-02-20_p180__RandomForestClassifier_190817_102843.pkl\n",
      "- Activating existing experiment 'benchmarks_time_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "- Experiment tracked.\n",
      "\n",
      "Experiment done!\n"
     ]
    }
   ],
   "source": [
    "experiment_time = models_loop(models, datafolder, prefixes_time, postfixes_time, \n",
    "                              timeSeqValid = True, train_window = 12000, test_window = 3000,\n",
    "                              mlf_tracking=True, save_model=True,\n",
    "                                experiment_name=expname, save_results_for_viz=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
