{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models loop automation - pastdue180 tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses as inputs the outputs from the pipeline 2 and performs model assessment of performances and general exploration for the transaction credit events prediction \"pastdue180\".  \n",
    "All the experiments produce useful data for visualizing results and can be tracked on MLflow.  \n",
    "The models' hyperparameters used at this stage have been tuned using random grid search in the notebook \"13_enriched_models_p180_tuning.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from models_utils import *\n",
    "from visualization_utils import *\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from bokeh.io import show, output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear model Stochastic Gradient Descent with optimized hyperparameters using random search\n",
    "sgd_rs = SGDClassifier(random_state=42, max_iter=300, loss='log', learning_rate='adaptive', eta0=0.01, tol=0.0001)\n",
    "sgd_rs_2 = SGDClassifier(random_state=42, max_iter=300, loss='log', learning_rate='optimal', eta0=0.0001, tol=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest models parameters from randomized grid search\n",
    "\n",
    "\n",
    "\n",
    "#first randomized search_imp\n",
    "rs1 = {'n_estimators': 280,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_leaf_nodes':60,\n",
    " 'max_depth': 100,\n",
    " 'bootstrap': True}\n",
    "\n",
    "#second randomized search_imp\n",
    "rs2 = {'n_estimators': 150,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_leaf_nodes': 60,\n",
    " 'max_features': 20,\n",
    " 'max_depth': 100,\n",
    " 'bootstrap': False}\n",
    "\n",
    "#third randomized search \n",
    "rs3 = {'n_estimators': 280,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_leaf_nodes': 60,\n",
    " 'max_features': 20,\n",
    " 'max_depth': 200,\n",
    " 'bootstrap': True}\n",
    "\n",
    "#third randomized search_p90\n",
    "rs4 = {'n_estimators': 150,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_leaf_nodes': 60,\n",
    " 'max_features': 20,\n",
    " 'max_depth': 100,\n",
    " 'bootstrap': False}\n",
    "\n",
    "#fourth randomized search_p90_bgt\n",
    "rs5={'n_estimators': 280,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_leaf_nodes': 60,\n",
    " 'max_features': 10,\n",
    " 'max_depth': 100,\n",
    " 'bootstrap': False}\n",
    "\n",
    "#fourth randomized search_p90_time\n",
    "rs6 = {'n_estimators': 300,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_leaf_nodes': 10,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 200,\n",
    " 'bootstrap': True}\n",
    "\n",
    "#seventh randomized search_p90_time bgt\n",
    "rs7={'n_estimators': 200,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_leaf_nodes': 20,\n",
    " 'max_features': 10,\n",
    " 'max_depth': None,\n",
    " 'bootstrap': True}\n",
    "\n",
    "#Best AUC 0.785 search_p90_time bgt\n",
    "rs8 = {'n_estimators': 250,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_leaf_nodes': 20,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': None,\n",
    " 'bootstrap': False}\n",
    "\n",
    "#Best AUC 0.797 search_p180_time bgt\n",
    "rs9={'n_estimators': 300,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_leaf_nodes': 40,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': None,\n",
    " 'bootstrap': True}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rf_rs_1 = RandomForestClassifier(random_state=42,\n",
    "                               n_estimators=rs1['n_estimators'],\n",
    "                               min_samples_split=rs1['min_samples_split'],\n",
    "                               min_samples_leaf=rs1['min_samples_leaf'],\n",
    "                               max_features = rs1['max_features'],\n",
    "                               max_leaf_nodes=rs1['max_leaf_nodes'],\n",
    "                               max_depth=rs1['max_depth'],\n",
    "                               bootstrap=rs1['bootstrap'],\n",
    "                               class_weight=\"balanced\",\n",
    "                               n_jobs=7)\n",
    "\n",
    "rf_rs_2 = RandomForestClassifier(random_state=42,\n",
    "                               n_estimators=rs2['n_estimators'],\n",
    "                               min_samples_split=rs2['min_samples_split'],\n",
    "                               min_samples_leaf=rs2['min_samples_leaf'],\n",
    "                               max_features = rs2['max_features'],\n",
    "                               max_leaf_nodes=rs2['max_leaf_nodes'],\n",
    "                               max_depth=rs2['max_depth'],\n",
    "                               bootstrap=rs2['bootstrap'],\n",
    "                               class_weight=\"balanced\",\n",
    "                               n_jobs=7)\n",
    "\n",
    "rf_rs_3 = RandomForestClassifier(random_state=42,\n",
    "                               n_estimators=rs3['n_estimators'],\n",
    "                               min_samples_split=rs3['min_samples_split'],\n",
    "                               min_samples_leaf=rs3['min_samples_leaf'],\n",
    "                               max_features = rs3['max_features'],\n",
    "                               max_leaf_nodes=rs3['max_leaf_nodes'],\n",
    "                               max_depth=rs3['max_depth'],\n",
    "                               bootstrap=rs3['bootstrap'],\n",
    "                               class_weight=\"balanced\",\n",
    "                               n_jobs=7)\n",
    "\n",
    "rf_rs_4 = RandomForestClassifier(random_state=42,\n",
    "                               n_estimators=rs4['n_estimators'],\n",
    "                               min_samples_split=rs4['min_samples_split'],\n",
    "                               min_samples_leaf=rs4['min_samples_leaf'],\n",
    "                               max_features = rs4['max_features'],\n",
    "                               max_leaf_nodes=rs4['max_leaf_nodes'],\n",
    "                               max_depth=rs4['max_depth'],\n",
    "                               bootstrap=rs4['bootstrap'],\n",
    "                               class_weight=\"balanced\",\n",
    "                               n_jobs=7)\n",
    "\n",
    "rf_rs_5 = RandomForestClassifier(random_state=42,\n",
    "                               n_estimators=rs5['n_estimators'],\n",
    "                               min_samples_split=rs5['min_samples_split'],\n",
    "                               min_samples_leaf=rs5['min_samples_leaf'],\n",
    "                               max_features = rs5['max_features'],\n",
    "                               max_leaf_nodes=rs5['max_leaf_nodes'],\n",
    "                               max_depth=rs5['max_depth'],\n",
    "                               bootstrap=rs5['bootstrap'],\n",
    "                               class_weight=\"balanced\",\n",
    "                               n_jobs=7)\n",
    "\n",
    "rf_rs_6 = RandomForestClassifier(random_state=42,\n",
    "                               n_estimators=rs6['n_estimators'],\n",
    "                               min_samples_split=rs6['min_samples_split'],\n",
    "                               min_samples_leaf=rs6['min_samples_leaf'],\n",
    "                               max_features = rs6['max_features'],\n",
    "                               max_leaf_nodes=rs6['max_leaf_nodes'],\n",
    "                               max_depth=rs6['max_depth'],\n",
    "                               bootstrap=rs6['bootstrap'],\n",
    "                               class_weight=\"balanced\",\n",
    "                               n_jobs=7)\n",
    "\n",
    "rf_rs_7 = RandomForestClassifier(random_state=42,\n",
    "                               n_estimators=rs7['n_estimators'],\n",
    "                               min_samples_split=rs7['min_samples_split'],\n",
    "                               min_samples_leaf=rs7['min_samples_leaf'],\n",
    "                               max_features = rs7['max_features'],\n",
    "                               max_leaf_nodes=rs7['max_leaf_nodes'],\n",
    "                               max_depth=rs7['max_depth'],\n",
    "                               bootstrap=rs7['bootstrap'],\n",
    "                               class_weight=\"balanced\",\n",
    "                               n_jobs=7)\n",
    "\n",
    "rf_rs_8 = RandomForestClassifier(random_state=42,\n",
    "                               n_estimators=rs8['n_estimators'],\n",
    "                               min_samples_split=rs8['min_samples_split'],\n",
    "                               min_samples_leaf=rs8['min_samples_leaf'],\n",
    "                               max_features = rs8['max_features'],\n",
    "                               max_leaf_nodes=rs8['max_leaf_nodes'],\n",
    "                               max_depth=rs8['max_depth'],\n",
    "                               bootstrap=rs8['bootstrap'],\n",
    "                               class_weight=\"balanced\",\n",
    "                               n_jobs=7)\n",
    "\n",
    "rf_rs_9 = RandomForestClassifier(random_state=42,\n",
    "                               n_estimators=rs9['n_estimators'],\n",
    "                               min_samples_split=rs9['min_samples_split'],\n",
    "                               min_samples_leaf=rs9['min_samples_leaf'],\n",
    "                               max_features = rs9['max_features'],\n",
    "                               max_leaf_nodes=rs9['max_leaf_nodes'],\n",
    "                               max_depth=rs9['max_depth'],\n",
    "                               bootstrap=rs9['bootstrap'],\n",
    "                               class_weight=\"balanced\",\n",
    "                               n_jobs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [sgd_rs, sgd_rs_2, rf_rs_1, rf_rs_2, rf_rs_3, rf_rs_4, rf_rs_5, rf_rs_6, rf_rs_7, rf_rs_8, rf_rs_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes_shuffle = ['shuffle_p180_bg_']\n",
    "postfixes_shuffle = ['_190721_1655']\n",
    "preproc_folder = \"enriched_shuffle\" #folder with the correct preprocessing data\n",
    "expname = preproc_folder+\"_opt_p180\" #experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = \"../data/preproc_traintest/\"+preproc_folder+'/'\n",
    "output_path = \"../data/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment in Shuffle Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.847\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.99481 0.00519]\n",
      " [0.06063 0.00751]]\n",
      "AUC 0.850\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__SGDClassifier_190721_2257.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__SGDClassifier_190721_2257_viz.pkl\n",
      "- Creating the new experiment 'enriched_shuffle_opt_p180',  the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.845\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.99305 0.00695]\n",
      " [0.05979 0.00834]]\n",
      "AUC 0.849\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__SGDClassifier_190721_2257.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__SGDClassifier_190721_2257_viz.pkl\n",
      "- Activating existing experiment 'enriched_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.974\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.92964 0.07036]\n",
      " [0.00519 0.06295]]\n",
      "AUC 0.976\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_2258.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_2258_viz.pkl\n",
      "- Activating existing experiment 'enriched_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.979\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.92204 0.07796]\n",
      " [0.00371 0.06443]]\n",
      "AUC 0.981\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_2259.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_2259_viz.pkl\n",
      "- Activating existing experiment 'enriched_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.979\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.92723 0.07277]\n",
      " [0.00436 0.06378]]\n",
      "AUC 0.981\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_231.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_231_viz.pkl\n",
      "- Activating existing experiment 'enriched_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.979\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.92204 0.07796]\n",
      " [0.00371 0.06443]]\n",
      "AUC 0.981\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_232.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_232_viz.pkl\n",
      "- Activating existing experiment 'enriched_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.978\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.93158 0.06842]\n",
      " [0.00464 0.0635 ]]\n",
      "AUC 0.980\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_233.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_233_viz.pkl\n",
      "- Activating existing experiment 'enriched_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.933\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.83304 0.16696]\n",
      " [0.00797 0.06017]]\n",
      "AUC 0.931\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_234.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_234_viz.pkl\n",
      "- Activating existing experiment 'enriched_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.959\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.91703 0.08297]\n",
      " [0.0064  0.06174]]\n",
      "AUC 0.959\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_234.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_234_viz.pkl\n",
      "- Activating existing experiment 'enriched_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.953\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.89144 0.10856]\n",
      " [0.00667 0.06146]]\n",
      "AUC 0.954\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_235.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_235_viz.pkl\n",
      "- Activating existing experiment 'enriched_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix shuffle_p180_bg_ and postfix _190721_1655 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__traindata_190721_1655.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_shuffle/shuffle_p180_bg__testdata_190721_1655.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.968\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.92194 0.07806]\n",
      " [0.00528 0.06285]]\n",
      "AUC 0.969\n",
      "- Saving the model to ../data/models/enriched_shuffle_opt_p180/...\n",
      "Saving model to ../data/models/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_236.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_shuffle_opt_p180/shuffle_p180_bg__RandomForestClassifier_190721_236_viz.pkl\n",
      "- Activating existing experiment 'enriched_shuffle_opt_p180', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_shuffle = models_loop(models, datafolder, prefixes_shuffle, postfixes_shuffle, mlf_tracking=True, save_model=True,\n",
    "                                experiment_name=expname, save_results_for_viz=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment in Time mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_folder = \"enriched_time\" #folder with the correct preprocessing data\n",
    "expname = preproc_folder+\"_opt_p180_bg_\" #experiment name\n",
    "datafolder = \"../data/preproc_traintest/\"+preproc_folder+'/'\n",
    "prefixes_time = ['time_2018-02-20_p180_bg_']\n",
    "postfixes_time = ['_190721_170']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.799\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.96067 0.03933]\n",
      " [0.00336 0.00013]]\n",
      "AUC 0.727\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__SGDClassifier_190721_236.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__SGDClassifier_190721_236_viz.pkl\n",
      "- Creating the new experiment 'enriched_time_opt_p180_bg_',  the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using SGDClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.796\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.95867 0.04133]\n",
      " [0.00336 0.00013]]\n",
      "AUC 0.731\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__SGDClassifier_190721_236.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__SGDClassifier_190721_236_viz.pkl\n",
      "- Activating existing experiment 'enriched_time_opt_p180_bg_', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.841\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.85238 0.14762]\n",
      " [0.00245 0.00103]]\n",
      "AUC 0.746\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_237.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_237_viz.pkl\n",
      "- Activating existing experiment 'enriched_time_opt_p180_bg_', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.773\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.83198 0.16802]\n",
      " [0.00174 0.00174]]\n",
      "AUC 0.802\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_238.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_238_viz.pkl\n",
      "- Activating existing experiment 'enriched_time_opt_p180_bg_', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.778\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.83669 0.16331]\n",
      " [0.002   0.00149]]\n",
      "AUC 0.789\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_239.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_239_viz.pkl\n",
      "- Activating existing experiment 'enriched_time_opt_p180_bg_', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.773\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.83198 0.16802]\n",
      " [0.00174 0.00174]]\n",
      "AUC 0.802\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2310.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2310_viz.pkl\n",
      "- Activating existing experiment 'enriched_time_opt_p180_bg_', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.823\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.83676 0.16324]\n",
      " [0.00245 0.00103]]\n",
      "AUC 0.765\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2312.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2312_viz.pkl\n",
      "- Activating existing experiment 'enriched_time_opt_p180_bg_', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.809\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.75481 0.24519]\n",
      " [0.00245 0.00103]]\n",
      "AUC 0.686\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2312.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2312_viz.pkl\n",
      "- Activating existing experiment 'enriched_time_opt_p180_bg_', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.809\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.79969 0.20031]\n",
      " [0.00245 0.00103]]\n",
      "AUC 0.710\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2313.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2313_viz.pkl\n",
      "- Activating existing experiment 'enriched_time_opt_p180_bg_', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.830\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.8015  0.1985 ]\n",
      " [0.00245 0.00103]]\n",
      "AUC 0.682\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2313.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2313_viz.pkl\n",
      "- Activating existing experiment 'enriched_time_opt_p180_bg_', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n",
      "Training, validation and testing of experiment with prefix time_2018-02-20_p180_bg_ and postfix _190721_170 using RandomForestClassifier\n",
      "-Loading preprocessed data...\n",
      "training files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__traindata_190721_170.pkl\n",
      "testing files: ../data/preproc_traintest/enriched_time/time_2018-02-20_p180_bg__testdata_190721_170.pkl\n",
      "- Training...\n",
      "- Validation...\n",
      "AUC 0.840\n",
      "- Testing...\n",
      "Confusion matrix: \n",
      "[[0.84625 0.15375]\n",
      " [0.00245 0.00103]]\n",
      "AUC 0.704\n",
      "- Saving the model to ../data/models/enriched_time_opt_p180_bg_/...\n",
      "Saving model to ../data/models/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2314.pkl\n",
      "Saving dictionary to ../data/viz_data/enriched_time_opt_p180_bg_/time_2018-02-20_p180_bg__RandomForestClassifier_190721_2314_viz.pkl\n",
      "- Activating existing experiment 'enriched_time_opt_p180_bg_', the following results will be saved in it...\n",
      "- Tracking the experiment on mlflow...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_time = models_loop(models, datafolder, prefixes_time, postfixes_time, mlf_tracking=True, save_model=True,\n",
    "                                experiment_name=expname, save_results_for_viz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
