{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "from scripts_ml.models_utils import *\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "from scripts_ml.ann_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "preproc_folder = \"enriched_time_seq\"\n",
    "datafolder = \"../data/preproc_traintest/\"+preproc_folder+'/'\n",
    "prefix_time_seq = 'time_2018-04-30_imp_bg_'\n",
    "valid_code = '_val_24000_6000_'\n",
    "trainfile = '_traindata'\n",
    "testfile = '_testdata'\n",
    "postfix_time_seq_val = '_190815_645'\n",
    "postfix_time_seq = '_190812_1547'\n",
    "preproc_folder = \"enriched_time_seq\"\n",
    "datafolder = \"../data/preproc_traintest/\"+preproc_folder+'/'\n",
    "indexfile = '_fold_indexes'\n",
    "expname = \"MLP_\"+preproc_folder+valid_code.split('_val_')[1][:-1]+\"_imp\"\n",
    "\n",
    "[X_train, y_train, feature_labels] = pd.read_pickle(datafolder+prefix_time_seq+trainfile+postfix_time_seq+'.pkl') \n",
    "[X_test, y_test, feature_labels] = pd.read_pickle(datafolder+prefix_time_seq+testfile+postfix_time_seq+'.pkl') \n",
    "[val_X_train, val_y_train, val_feature_labels] = pd.read_pickle(datafolder+prefix_time_seq+valid_code+trainfile+postfix_time_seq_val+'.pkl') \n",
    "[val_X_test, val_y_test, val_feature_labels] = pd.read_pickle(datafolder+prefix_time_seq+valid_code+testfile+postfix_time_seq_val+'.pkl') \n",
    "indexes = pd.read_pickle(datafolder+prefix_time_seq+valid_code+indexfile+postfix_time_seq_val+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recombining folds for grid search\n",
    "\n",
    "val_X_all = []\n",
    "val_y_all = []\n",
    "indexes_tuples = []\n",
    "\n",
    "count=0\n",
    "start_tr=0\n",
    "\n",
    "for idx in indexes:\n",
    "    val_X_all.append(val_X_train[idx[0]])\n",
    "    val_y_all.append(val_y_train[idx[0]])\n",
    "    if count==0:\n",
    "        test_idx = np.array(range(0, len(idx[1])))\n",
    "    else:\n",
    "        test_idx+=len(idx[1])\n",
    "    val_X_all.append(val_X_test[test_idx])\n",
    "    val_y_all.append(val_y_test[test_idx])\n",
    "    \n",
    "    \n",
    "    if count==0:\n",
    "        start_tst = len(idx[0])\n",
    "    else:\n",
    "        start_tr+=add_to_tr\n",
    "        start_tst=start_tr+len(idx[0])\n",
    "        \n",
    "    indexes_tuples.append((np.array(range(start_tr, start_tr+len(idx[0]))), \n",
    "                          np.array(range(start_tst, start_tst+len(idx[1])))))\n",
    "    \n",
    "    add_to_tr = len(idx[0])+len(idx[1])\n",
    "    \n",
    "    count+=1\n",
    "\n",
    "val_X_all = np.concatenate(val_X_all, axis=0)\n",
    "val_y_all = np.concatenate(val_y_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp = create_mlp_model(input_shape = X_train.shape[0],\n",
    "#                     hidden_layers_no=1, \n",
    "#                     hidden_nodes=[5], \n",
    "#                     hl_activations = [tf.nn.relu], \n",
    "#                     random_seed=42, \n",
    " #                    output_function = tf.nn.sigmoid,\n",
    " #                    optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    " #                    loss_func = 'binary_crossentropy',\n",
    " #                    metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
    " #                    kernel_regularizers = [],\n",
    " #                    kernel_initializer = tf.keras.initializers.lecun_uniform(seed=42),\n",
    " #                    bias_initializer = tf.keras.initializers.Zeros(),\n",
    " #                    dropout = None,\n",
    " #                   print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = KerasClassifier(build_fn=create_mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [X_train.shape[1]]\n",
    "\n",
    "hidden_layers_no = [2] \n",
    "\n",
    "hidden_nodes = [[5,5], [10,5], \n",
    "                [20,5], [20,10], \n",
    "                [50,5], [50,10], [50,20],\n",
    "               [80,5], [80,10], [80,20]] \n",
    "\n",
    "hl_activations = [[tf.nn.relu]*2]\n",
    "\n",
    "dropout = [[0.3]*2, [0.4]*2, [0.5]*2, [0.6]*2, None]\n",
    "\n",
    "optimizer = [RMSprop(), Adam(), SGD()]\n",
    "\n",
    "batch_size = [128, 256, 512, 1024, 2048]\n",
    "\n",
    "nb_epoch = [50, 100, 200, 500]\n",
    "\n",
    "param_grid = {'hidden_layers_no': hidden_layers_no,\n",
    "               'hidden_nodes': hidden_nodes,\n",
    "               'hl_activations': hl_activations,\n",
    "              'dropout': dropout,\n",
    "               'input_shape': input_shape,\n",
    "               'optimizer': optimizer,\n",
    "               'batch_size': batch_size,\n",
    "              'nb_epoch':nb_epoch,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\"AUC\": \"roc_auc\", \"Accuracy\": make_scorer(accuracy_score)}\n",
    "\n",
    "mlp_grid = GridSearchCV(estimator = mlp, param_grid = param_grid, \n",
    "                               cv = rolling_window_idxs(indexes_tuples), \n",
    "                               verbose=1, n_jobs =7, scoring=scoring, refit='AUC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3000 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  1.8min\n"
     ]
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "mlp_grid.fit(val_X_all, val_y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlp_exp_timeseq(datafolder, prefix_time_seq, postfix_time_seq,\n",
    "                postfix_time_seq_val, valid_code, indexfile,\n",
    "                         experiment_name=expname, \n",
    "                         hidden_layers_no=2,  #4\n",
    "                         hidden_nodes=[50, 20, 10],       \n",
    "                         optimizer=Adam(0.0001),\n",
    "                         hl_activations=[tf.nn.relu]*2,      \n",
    "                         dropout=[0.4]*2,            \n",
    "                         loss_func = tf.keras.losses.BinaryCrossentropy(),\n",
    "                         metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
    "                         to_monitor=('accuracy', 0.98),\n",
    "                         validation_ep=True,\n",
    "                         epochs=3000, \n",
    "                         batch_size=2048,\n",
    "                         use_batch_and_steps=False,\n",
    "                         class_1_weight=25,\n",
    "                         pred_threshold = 0.55,\n",
    "                         verbose=0,\n",
    "                         early_stopping=False, \n",
    "                         save_model=True, \n",
    "                         save_results_for_viz=False,\n",
    "                         mlf_tracking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
