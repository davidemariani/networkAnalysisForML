{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline 2 - bond graph features models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook starts from the output at step 10 (10_network_featureEng.ipynb) in order to prepare the data to be put into the new bond graph featured models for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "from scripts_ml.preprocessing_pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data and main settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = \"../data/\"\n",
    "inputfilename = '04_instrumentsdf_bondgraph.pkl'\n",
    "\n",
    "df = pd.read_pickle(datafolder+inputfilename)\n",
    "\n",
    "#feature selection\n",
    "feat_str = [] #enforced single column for each currency and enclosed in feat_quant for timeseq step\n",
    "feat_quant = ['currency_Schweizer Franken', 'currency_Euro', 'currency_US-Dollar', 'currency_Britisches Pfund',\n",
    "              'has_purchase', 'dd_value_date', 'cd_lent_c', 'cd_repaid_c', 'cd_impaired1_c', 'cd_pastdue90_c', 'cd_trend_a', 'c_lent_c', 'c_repaid_c', 'c_impaired1_c', \n",
    "              'c_pastdue90_c', 'c_trend_a', 'd_repaid_c', 'd_impaired1_c', 'd_pastdue90_c', 'd_trend_a', 'd_we_payment_share', 'flow_shock_imp1', 'imp_c_node_eff', 'imp_energy', 'imp_d_node_flow', \n",
    "              'flow_shock_p90', 'p90_c_node_eff', 'p90_energy', 'p90_d_node_flow', 'flow_shock_p180', 'p180_d_node_flow', 'p180_energy']\n",
    "feat_exp = ['invoice_amount', 'purchase_amount']\n",
    "feat_date = ['invoice_date']\n",
    "\n",
    "#settings\n",
    "targets = ['has_impairment1', 'is_pastdue90', 'is_pastdue180']\n",
    "\n",
    "pfixes = ['imp_bg_', 'p90_bg_', 'p180_bg_']\n",
    "\n",
    "output_path = datafolder+\"/preproc_traintest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name_1</th>\n",
       "      <th>debtor_id</th>\n",
       "      <th>debtor_name_1</th>\n",
       "      <th>invoice_number</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>due_date</th>\n",
       "      <th>invoice_amount</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_amount_open</th>\n",
       "      <th>...</th>\n",
       "      <th>p90_c_node_eff</th>\n",
       "      <th>p90_node_flow</th>\n",
       "      <th>p90_energy</th>\n",
       "      <th>flow_shock_p90</th>\n",
       "      <th>p180_edge_flow</th>\n",
       "      <th>p180_d_node_flow</th>\n",
       "      <th>p180_c_node_eff</th>\n",
       "      <th>p180_node_flow</th>\n",
       "      <th>p180_energy</th>\n",
       "      <th>flow_shock_p180</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2744:79/231</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2744</td>\n",
       "      <td>2013-07-23</td>\n",
       "      <td>2013-08-02</td>\n",
       "      <td>913.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861:79/232</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2861</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>2013-08-09</td>\n",
       "      <td>2233.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932:79/233</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2932</td>\n",
       "      <td>2013-08-06</td>\n",
       "      <td>2013-08-16</td>\n",
       "      <td>1370.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472:489/688</th>\n",
       "      <td>2004009</td>\n",
       "      <td>Orpheus Wyandotte Supply LLC</td>\n",
       "      <td>489</td>\n",
       "      <td>Isfahan SA</td>\n",
       "      <td>1472</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>9195.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>1.665866</td>\n",
       "      <td>366437.206374</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>0.54333</td>\n",
       "      <td>119515.16508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042:512/645</th>\n",
       "      <td>2004009</td>\n",
       "      <td>Orpheus Wyandotte Supply LLC</td>\n",
       "      <td>512</td>\n",
       "      <td>Aldrich Chloe GmbH</td>\n",
       "      <td>2042</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>4594.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>1.665866</td>\n",
       "      <td>366437.206374</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>0.54333</td>\n",
       "      <td>119515.16508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             customer_id               customer_name_1 debtor_id  \\\n",
       "uid                                                                \n",
       "2744:79/231      2004008                 Castillo GmbH        79   \n",
       "2861:79/232      2004008                 Castillo GmbH        79   \n",
       "2932:79/233      2004008                 Castillo GmbH        79   \n",
       "1472:489/688     2004009  Orpheus Wyandotte Supply LLC       489   \n",
       "2042:512/645     2004009  Orpheus Wyandotte Supply LLC       512   \n",
       "\n",
       "                   debtor_name_1 invoice_number invoice_date   due_date  \\\n",
       "uid                                                                       \n",
       "2744:79/231    Sana Hyannis Sarl           2744   2013-07-23 2013-08-02   \n",
       "2861:79/232    Sana Hyannis Sarl           2861   2013-07-30 2013-08-09   \n",
       "2932:79/233    Sana Hyannis Sarl           2932   2013-08-06 2013-08-16   \n",
       "1472:489/688          Isfahan SA           1472   2013-08-13 2013-08-23   \n",
       "2042:512/645  Aldrich Chloe GmbH           2042   2013-08-13 2013-08-23   \n",
       "\n",
       "              invoice_amount  purchase_amount  purchase_amount_open  ...  \\\n",
       "uid                                                                  ...   \n",
       "2744:79/231           913.70              0.0                   0.0  ...   \n",
       "2861:79/232          2233.45              0.0                   0.0  ...   \n",
       "2932:79/233          1370.50              0.0                   0.0  ...   \n",
       "1472:489/688         9195.10              0.0                   0.0  ...   \n",
       "2042:512/645         4594.60              0.0                   0.0  ...   \n",
       "\n",
       "             p90_c_node_eff  p90_node_flow     p90_energy flow_shock_p90  \\\n",
       "uid                                                                        \n",
       "2744:79/231        239912.0       0.000000       0.000000            1.0   \n",
       "2861:79/232        239912.0       0.000000       0.000000            1.0   \n",
       "2932:79/233        239912.0       0.000000       0.000000            1.0   \n",
       "1472:489/688       234247.0       1.665866  366437.206374           36.0   \n",
       "2042:512/645       234247.0       1.665866  366437.206374           36.0   \n",
       "\n",
       "             p180_edge_flow  p180_d_node_flow p180_c_node_eff p180_node_flow  \\\n",
       "uid                                                                            \n",
       "2744:79/231             0.0               0.0        239912.0        0.00000   \n",
       "2861:79/232             0.0               0.0        239912.0        0.00000   \n",
       "2932:79/233             0.0               0.0        239912.0        0.00000   \n",
       "1472:489/688            0.0               0.0        234247.0        0.54333   \n",
       "2042:512/645            0.0               0.0        234247.0        0.54333   \n",
       "\n",
       "               p180_energy flow_shock_p180  \n",
       "uid                                         \n",
       "2744:79/231        0.00000             1.0  \n",
       "2861:79/232        0.00000             1.0  \n",
       "2932:79/233        0.00000             1.0  \n",
       "1472:489/688  119515.16508             1.0  \n",
       "2042:512/645  119515.16508             1.0  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all instruments that are not due yet, since they can't be labelled\n",
    "#print(\"{:} instruments that are not due yet, dropping...\".format(sum(~df.is_due)))\n",
    "#df=df.loc[df.is_due, :]\n",
    "#print(\"{:} instruments remaining\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating preprocessed data for impairment, pastdue90 and pastdue180 credit events - Shuffle mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(targets)):\n",
    "    y_train, X_train, y_test, X_test, feature_labels = preprocessing_pipeline(df, feat_str, feat_quant, feat_exp, feat_date, targets[t], 'invoice_date', \n",
    "                                                                              'enriched_shuffle', trainsize = .8, testsize = .2, #int(df.shape[0]*.80) int(df.shape[0]*.20)-1,\n",
    "                                                                         save_to_file=True, outputpath=output_path, prefix=pfixes[t],\n",
    "                                                                             decompose_currency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating preprocessed data for impairment, pastdue90 and pastdue180 credit events - Timewise mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(targets)):\n",
    "    if t!=2:\n",
    "        tdate = datetime.datetime(2018, 4, 30)\n",
    "        y_train, X_train, y_test, X_test, feature_labels = preprocessing_pipeline(df, feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                             'invoice_date', 'enriched_time', timewise=True, testdate = tdate,\n",
    "                                                                             save_to_file=True, outputpath=output_path, prefix=pfixes[t],\n",
    "                                                                                 decompose_currency=True)\n",
    "    else:\n",
    "        tdate = datetime.datetime(2018, 2, 20)\n",
    "        y_train, X_train, y_test, X_test, feature_labels = preprocessing_pipeline(df, feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                             'invoice_date', 'enriched_time', timewise=True, testdate = tdate,\n",
    "                                                                             save_to_file=True, outputpath=output_path, prefix=pfixes[t],\n",
    "                                                                                 decompose_currency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating preprocessed data for impairment, pastdue90 and pastdue180 credit events - Sequential Timewise mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposing currency column to multiple columns with boolean values...\n",
      "---------MACRO TRAIN SPLIT-----------\n",
      "2201 instruments that are not due yet, dropping...\n",
      "57619 instruments remaining\n",
      "Splitting train and test sets by time, test cutoff: 2018-04-30 00:00:00...\n",
      "  46101(80.0%) train, 11518(20.0%) test\n",
      "---------Sequential validation splits-----------\n",
      "Preparing fold 0 with 26101 train observations and 2000 test observations, starti=2101...\n",
      "---------Train test for validation fold 0-----------\n",
      "---------Adding bond graph features 1 of 3 to TRAIN SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (26101, 114)...\n",
      "Starting bg features - dataset shape: (26101, 116)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (26101, 120)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1047 graphs successfully created\n",
      "Total calculated shock flow is 1199 over 17 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (26101, 121)\n",
      "Done!\n",
      "---------Adding bond graph features 1 of 3 to TEST SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 114)...\n",
      "Starting bg features - dataset shape: (28101, 116)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 120)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1118 graphs successfully created\n",
      "Total calculated shock flow is 8904 over 89 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 121)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TRAIN SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (26101, 121)...\n",
      "Starting bg features - dataset shape: (26101, 123)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (26101, 127)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1056 graphs successfully created\n",
      "Total calculated shock flow is 1 over 1 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (26101, 128)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TEST SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 121)...\n",
      "Starting bg features - dataset shape: (28101, 123)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 127)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1127 graphs successfully created\n",
      "Total calculated shock flow is 1 over 1 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 128)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TRAIN SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (26101, 128)...\n",
      "Starting bg features - dataset shape: (26101, 130)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n"
     ]
    }
   ],
   "source": [
    "#changing input dataset for the sequential time split\n",
    "inputfilename = '03_instrumentsdf_deg1stats.pkl'\n",
    "df = pd.read_pickle(datafolder+inputfilename)\n",
    "\n",
    "train_window = 26000 #16000, 30000, 24000 #\n",
    "test_window = 2000 #4000, 6000, 6000\n",
    "\n",
    "bond_graph_settings = [\n",
    "    #impairment settings\n",
    "    {'col_to_calc_effort' : 'purchase_amount',\n",
    "    'effort_col' : 'imp_edge_eff', \n",
    "    'flow_col' : 'imp_edge_flow', \n",
    "    'col_to_calc_flow' : 'total_impairment',\n",
    "     'col_ratio_flow' : 'invoice_amount',\n",
    "     'col_mult_flow': None,\n",
    "    'node_flow_col' : 'imp_node_flow', \n",
    "    'energy_col' : 'imp_energy', \n",
    "    'c_node_eff_col' : 'imp_c_node_eff',\n",
    "    'd_node_flow_col' : 'imp_d_node_flow', \n",
    "    'shock_col' : 'flow_shock_imp1',\n",
    "    'red_coeff' : 10**6},\n",
    "    \n",
    "    #pastdue90 settings\n",
    "    {'col_to_calc_effort' : 'cd_lent_c',#'payment_date_mismatch',\n",
    "    'effort_col' : 'p90_edge_eff', \n",
    "    'flow_col' : 'p90_edge_flow', \n",
    "    'col_to_calc_flow' : 'payment_date_mismatch',#'cd_pastdue90_r',\n",
    "     'col_ratio_flow' : None,\n",
    "     'col_mult_flow': 'cd_pastdue90_r',\n",
    "    'node_flow_col' : 'p90_node_flow', \n",
    "    'energy_col' : 'p90_energy', \n",
    "    'c_node_eff_col' : 'p90_c_node_eff',\n",
    "    'd_node_flow_col' : 'p90_d_node_flow', \n",
    "    'shock_col' : 'flow_shock_p90',\n",
    "    'red_coeff' : 10**10 #10**4\n",
    "    },\n",
    "    \n",
    "    #pastdue180 settings\n",
    "    {'col_to_calc_effort' : 'cd_lent_c', #'payment_date_mismatch',\n",
    "    'effort_col' : 'p180_edge_eff', \n",
    "    'flow_col' : 'p180_edge_flow', \n",
    "    'col_to_calc_flow' : 'payment_date_mismatch',\n",
    "     'col_ratio_flow' : None,\n",
    "     'col_mult_flow': 'cd_pastdue180_r',\n",
    "    'node_flow_col' : 'p180_node_flow', \n",
    "    'energy_col' : 'p180_energy', \n",
    "    'c_node_eff_col' : 'p180_c_node_eff',\n",
    "    'd_node_flow_col' : 'p180_d_node_flow', \n",
    "    'shock_col' : 'flow_shock_p180',\n",
    "    'red_coeff' : 10**10 #10**5\n",
    "    }\n",
    "]\n",
    "\n",
    "for t in range(len(targets)):\n",
    "    if targets[t]!='is_pastdue180':\n",
    "        tdate = datetime.datetime(2018, 4, 30)\n",
    "          #y_valid_train, X_valid_train, y_valid_test, X_valid_test, feature_labels, folds_idx  ###only validation folds ---> validation_prep_only=True\n",
    "        #y_train, X_train, y_test, X_test, feature_labels, y_valid_train, X_valid_train, y_valid_test, X_valid_test, folds_idx ###both train test and validation folds ---> validation_prep_only=False and train_test_prep_only=False\n",
    "        #y_train, X_train, y_test, X_test, feature_labels ###only train test ---> train_test_prep_only=True\n",
    "        \n",
    "        y_valid_train, X_valid_train, y_valid_test, X_valid_test, feature_labels, folds_idx= preproc_pipeline_timeseq(df, \n",
    "                                                                                   feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                                 'invoice_date', 'enriched_time_seq', bond_graph_settings, testdate = tdate,\n",
    "                                                                                train_window=train_window, test_window=test_window,\n",
    "                                                                                   use_previous_whole_bg = True,\n",
    "                                                                                   whole_network_with_bg_file_path=\"../data/04_instrumentsdf_bondgraph2.pkl\",\n",
    "                                                                             save_to_file=True, outputpath=output_path, prefix=pfixes[t],\n",
    "                                                                                    export_whole_network=False,\n",
    "                                                                                    #whole_network_output_path=\"../data/04_instrumentsdf_bondgraph2.pkl\",\n",
    "                                                                                   decompose_currency=True, \n",
    "                                                                                   validation_prep_only=True, \n",
    "                                                                                   train_test_prep_only=False)\n",
    "    else:\n",
    "        tdate = datetime.datetime(2018, 2, 20)\n",
    "\n",
    "        y_valid_train, X_valid_train, y_valid_test, X_valid_test, feature_labels, folds_idx= preproc_pipeline_timeseq(df, \n",
    "                                                                                   feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                                 'invoice_date', 'enriched_time_seq', bond_graph_settings, testdate = tdate,\n",
    "                                                                                train_window=train_window, test_window=test_window,\n",
    "                                                                                   use_previous_whole_bg = True,\n",
    "                                                                                   whole_network_with_bg_file_path=\"../data/04_instrumentsdf_bondgraph2.pkl\",\n",
    "                                                                             save_to_file=True, outputpath=output_path, prefix=pfixes[t],\n",
    "                                                                                    export_whole_network=False,\n",
    "                                                                                    #whole_network_output_path=\"../data/04_instrumentsdf_bondgraph2.pkl\",\n",
    "                                                                                   decompose_currency=True, \n",
    "                                                                                   validation_prep_only=True, \n",
    "                                                                                   train_test_prep_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx = []\n",
    "#testx = []\n",
    "#for count, train, test, boh in rolling_window(df.shape[0], 12000, 3000):\n",
    "#    if count==5:\n",
    "#        trainx=train\n",
    "#        testx=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 110)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[testx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
