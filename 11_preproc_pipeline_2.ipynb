{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline 2 - bond graph features models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook starts from the output at step 10 (10_network_featureEng.ipynb) in order to prepare the data to be put into the new bond graph featured models for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "from scripts_ml.preprocessing_pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data and main settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = \"../data/\"\n",
    "inputfilename = '04_instrumentsdf_bondgraph.pkl'\n",
    "\n",
    "df = pd.read_pickle(datafolder+inputfilename)\n",
    "\n",
    "#feature selection\n",
    "feat_str = [] #enforced single column for each currency and enclosed in feat_quant for timeseq step\n",
    "feat_quant = ['currency_Schweizer Franken', 'currency_Euro', 'currency_US-Dollar', 'currency_Britisches Pfund',\n",
    "              'has_purchase', 'dd_value_date', 'cd_lent_c', 'cd_repaid_c', 'cd_impaired1_c', 'cd_pastdue90_c', 'cd_trend_a', 'c_lent_c', 'c_repaid_c', 'c_impaired1_c', \n",
    "              'c_pastdue90_c', 'c_trend_a', 'd_repaid_c', 'd_impaired1_c', 'd_pastdue90_c', 'd_trend_a', 'd_we_payment_share', 'flow_shock_imp1', 'imp_c_node_eff', 'imp_energy', 'imp_d_node_flow', \n",
    "              'flow_shock_p90', 'p90_c_node_eff', 'p90_energy', 'p90_d_node_flow', 'flow_shock_p180', 'p180_d_node_flow', 'p180_energy']\n",
    "feat_exp = ['invoice_amount', 'purchase_amount']\n",
    "feat_date = ['invoice_date']\n",
    "\n",
    "#settings\n",
    "targets = ['has_impairment1', 'is_pastdue90', 'is_pastdue180']\n",
    "\n",
    "pfixes = ['imp_bg_', 'p90_bg_', 'p180_bg_']\n",
    "\n",
    "output_path = datafolder+\"/preproc_traintest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name_1</th>\n",
       "      <th>debtor_id</th>\n",
       "      <th>debtor_name_1</th>\n",
       "      <th>invoice_number</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>due_date</th>\n",
       "      <th>invoice_amount</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_amount_open</th>\n",
       "      <th>...</th>\n",
       "      <th>p90_c_node_eff</th>\n",
       "      <th>p90_node_flow</th>\n",
       "      <th>p90_energy</th>\n",
       "      <th>flow_shock_p90</th>\n",
       "      <th>p180_edge_flow</th>\n",
       "      <th>p180_d_node_flow</th>\n",
       "      <th>p180_c_node_eff</th>\n",
       "      <th>p180_node_flow</th>\n",
       "      <th>p180_energy</th>\n",
       "      <th>flow_shock_p180</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2744:79/231</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2744</td>\n",
       "      <td>2013-07-23</td>\n",
       "      <td>2013-08-02</td>\n",
       "      <td>913.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861:79/232</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2861</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>2013-08-09</td>\n",
       "      <td>2233.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932:79/233</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2932</td>\n",
       "      <td>2013-08-06</td>\n",
       "      <td>2013-08-16</td>\n",
       "      <td>1370.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472:489/688</th>\n",
       "      <td>2004009</td>\n",
       "      <td>Orpheus Wyandotte Supply LLC</td>\n",
       "      <td>489</td>\n",
       "      <td>Isfahan SA</td>\n",
       "      <td>1472</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>9195.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>1.665866</td>\n",
       "      <td>366437.206374</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>0.54333</td>\n",
       "      <td>119515.16508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042:512/645</th>\n",
       "      <td>2004009</td>\n",
       "      <td>Orpheus Wyandotte Supply LLC</td>\n",
       "      <td>512</td>\n",
       "      <td>Aldrich Chloe GmbH</td>\n",
       "      <td>2042</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>4594.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>1.665866</td>\n",
       "      <td>366437.206374</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>0.54333</td>\n",
       "      <td>119515.16508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             customer_id               customer_name_1 debtor_id  \\\n",
       "uid                                                                \n",
       "2744:79/231      2004008                 Castillo GmbH        79   \n",
       "2861:79/232      2004008                 Castillo GmbH        79   \n",
       "2932:79/233      2004008                 Castillo GmbH        79   \n",
       "1472:489/688     2004009  Orpheus Wyandotte Supply LLC       489   \n",
       "2042:512/645     2004009  Orpheus Wyandotte Supply LLC       512   \n",
       "\n",
       "                   debtor_name_1 invoice_number invoice_date   due_date  \\\n",
       "uid                                                                       \n",
       "2744:79/231    Sana Hyannis Sarl           2744   2013-07-23 2013-08-02   \n",
       "2861:79/232    Sana Hyannis Sarl           2861   2013-07-30 2013-08-09   \n",
       "2932:79/233    Sana Hyannis Sarl           2932   2013-08-06 2013-08-16   \n",
       "1472:489/688          Isfahan SA           1472   2013-08-13 2013-08-23   \n",
       "2042:512/645  Aldrich Chloe GmbH           2042   2013-08-13 2013-08-23   \n",
       "\n",
       "              invoice_amount  purchase_amount  purchase_amount_open  ...  \\\n",
       "uid                                                                  ...   \n",
       "2744:79/231           913.70              0.0                   0.0  ...   \n",
       "2861:79/232          2233.45              0.0                   0.0  ...   \n",
       "2932:79/233          1370.50              0.0                   0.0  ...   \n",
       "1472:489/688         9195.10              0.0                   0.0  ...   \n",
       "2042:512/645         4594.60              0.0                   0.0  ...   \n",
       "\n",
       "             p90_c_node_eff  p90_node_flow     p90_energy flow_shock_p90  \\\n",
       "uid                                                                        \n",
       "2744:79/231        239912.0       0.000000       0.000000            1.0   \n",
       "2861:79/232        239912.0       0.000000       0.000000            1.0   \n",
       "2932:79/233        239912.0       0.000000       0.000000            1.0   \n",
       "1472:489/688       234247.0       1.665866  366437.206374           36.0   \n",
       "2042:512/645       234247.0       1.665866  366437.206374           36.0   \n",
       "\n",
       "             p180_edge_flow  p180_d_node_flow p180_c_node_eff p180_node_flow  \\\n",
       "uid                                                                            \n",
       "2744:79/231             0.0               0.0        239912.0        0.00000   \n",
       "2861:79/232             0.0               0.0        239912.0        0.00000   \n",
       "2932:79/233             0.0               0.0        239912.0        0.00000   \n",
       "1472:489/688            0.0               0.0        234247.0        0.54333   \n",
       "2042:512/645            0.0               0.0        234247.0        0.54333   \n",
       "\n",
       "               p180_energy flow_shock_p180  \n",
       "uid                                         \n",
       "2744:79/231        0.00000             1.0  \n",
       "2861:79/232        0.00000             1.0  \n",
       "2932:79/233        0.00000             1.0  \n",
       "1472:489/688  119515.16508             1.0  \n",
       "2042:512/645  119515.16508             1.0  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all instruments that are not due yet, since they can't be labelled\n",
    "#print(\"{:} instruments that are not due yet, dropping...\".format(sum(~df.is_due)))\n",
    "#df=df.loc[df.is_due, :]\n",
    "#print(\"{:} instruments remaining\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating preprocessed data for impairment, pastdue90 and pastdue180 credit events - Shuffle mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(targets)):\n",
    "    y_train, X_train, y_test, X_test, feature_labels = preprocessing_pipeline(df, feat_str, feat_quant, feat_exp, feat_date, targets[t], 'invoice_date', \n",
    "                                                                              'enriched_shuffle', trainsize = .8, testsize = .2, #int(df.shape[0]*.80) int(df.shape[0]*.20)-1,\n",
    "                                                                         save_to_file=True, outputpath=output_path, prefix=pfixes[t],\n",
    "                                                                             decompose_currency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating preprocessed data for impairment, pastdue90 and pastdue180 credit events - Timewise mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(targets)):\n",
    "    if t!=2:\n",
    "        tdate = datetime.datetime(2018, 4, 30)\n",
    "        y_train, X_train, y_test, X_test, feature_labels = preprocessing_pipeline(df, feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                             'invoice_date', 'enriched_time', timewise=True, testdate = tdate,\n",
    "                                                                             save_to_file=True, outputpath=output_path, prefix=pfixes[t],\n",
    "                                                                                 decompose_currency=True)\n",
    "    else:\n",
    "        tdate = datetime.datetime(2018, 2, 20)\n",
    "        y_train, X_train, y_test, X_test, feature_labels = preprocessing_pipeline(df, feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                             'invoice_date', 'enriched_time', timewise=True, testdate = tdate,\n",
    "                                                                             save_to_file=True, outputpath=output_path, prefix=pfixes[t],\n",
    "                                                                                 decompose_currency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating preprocessed data for impairment, pastdue90 and pastdue180 credit events - Sequential Timewise mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposing currency column to multiple columns with boolean values...\n",
      "---------Macro train split-----------\n",
      "2201 instruments that are not due yet, dropping...\n",
      "57619 instruments remaining\n",
      "Splitting train and test sets by time, test cutoff: 2018-04-30 00:00:00...\n",
      "  46101(80.0%) train, 11518(20.0%) test\n",
      "---------Adding bond graph features 1 of 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 114)...\n",
      "Starting bg features - dataset shape: (46101, 116)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 120)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1489 graphs successfully created\n",
      "Total calculated shock flow is 580601 over 119 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (46101, 121)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 121)...\n",
      "Starting bg features - dataset shape: (46101, 123)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 127)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1337 graphs successfully created\n",
      "Total calculated shock flow is 51830 over 19 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (46101, 128)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 128)...\n",
      "Starting bg features - dataset shape: (46101, 130)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 134)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1308 graphs successfully created\n",
      "Total calculated shock flow is 1716 over 18 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (46101, 135)\n",
      "Done!\n",
      "---------Macro test split-----------\n",
      "Decomposing currency column from full dataset to multiple columns with boolean values...\n",
      "2201 instruments that are not due yet, dropping...\n",
      "57619 instruments remaining\n",
      "Splitting train and test sets by time, test cutoff: 2018-04-30 00:00:00...\n",
      "  46101(80.0%) train, 11518(20.0%) test\n",
      "---------Pipeline application-----------\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 46101 total, 710 class_1 observations (1.54%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 11518 total, 485 class_1 observations (4.21%) > 0\n",
      "pipeline transform only for test set...\n",
      "---------Macro train-test saving-----------\n",
      "Saving with file name prefix time_2018-04-30_imp_bg_ and postfix _190822_857...\n",
      "...done.\n",
      "---------Sequential validation splits-----------\n",
      "Preparing fold 0 with 28101 train observations and 6000 test observations, starti=10101...\n",
      "---------Train test for validation fold 0-----------\n",
      "---------Adding bond graph features 1 of 3 to TRAIN SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 114)...\n",
      "Starting bg features - dataset shape: (28101, 116)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 120)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1118 graphs successfully created\n",
      "Total calculated shock flow is 8904 over 89 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 121)\n",
      "Done!\n",
      "---------Adding bond graph features 1 of 3 to TEST SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (34101, 114)...\n",
      "Starting bg features - dataset shape: (34101, 116)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (34101, 120)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1264 graphs successfully created\n",
      "Total calculated shock flow is 74394 over 101 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (34101, 121)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TRAIN SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 121)...\n",
      "Starting bg features - dataset shape: (28101, 123)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 127)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1010 graphs successfully created\n",
      "Total calculated shock flow is 4 over 3 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 128)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TEST SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (34101, 121)...\n",
      "Starting bg features - dataset shape: (34101, 123)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (34101, 127)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1139 graphs successfully created\n",
      "Total calculated shock flow is 0 over 0 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (34101, 128)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TRAIN SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 128)...\n",
      "Starting bg features - dataset shape: (28101, 130)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 134)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "6 graphs successfully created\n",
      "Total calculated shock flow is 2 over 2 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 135)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TEST SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (34101, 128)...\n",
      "Starting bg features - dataset shape: (34101, 130)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (34101, 134)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "6 graphs successfully created\n",
      "Total calculated shock flow is 2 over 2 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (34101, 135)\n",
      "Done!\n",
      "----------SHAPE SANITY CHECK--------\n",
      "Training dataset shape before preprocessing pipeline: (28101, 135)\n",
      "Test dataset shape before preprocessing pipeline: (6000, 135)\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 28101 total, 395 class_1 observations (1.41%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 6000 total, 70 class_1 observations (1.17%) > 0\n",
      "pipeline transform only for test set...\n",
      "Creating first fold with X_train of shape (28101, 35), y_train of shape (28101,), X_test of shape (6000, 35) and y_test of shape (6000,)...\n",
      "\n",
      "Preparing fold 1 with 24000 train observations and 6000 test observations, starti=16101...\n",
      "---------Train test for validation fold 1-----------\n",
      "---------Using test df for bond graph features from fold 0 to create TRAIN SET for fold 1-----------\n",
      "Checking train set shape: (34101, 135)\n",
      "---------Adding bond graph features 1 of 3 to TEST SET for fold 1-----------\n",
      "Calculating effort and flow for starting dataset with shape (40101, 114)...\n",
      "Starting bg features - dataset shape: (40101, 116)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (40101, 120)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1454 graphs successfully created\n",
      "Total calculated shock flow is 214512 over 111 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (40101, 121)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TEST SET for fold 1-----------\n",
      "Calculating effort and flow for starting dataset with shape (40101, 121)...\n",
      "Starting bg features - dataset shape: (40101, 123)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (40101, 127)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1305 graphs successfully created\n",
      "Total calculated shock flow is 6880 over 16 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (40101, 128)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TEST SET for fold 1-----------\n",
      "Calculating effort and flow for starting dataset with shape (40101, 128)...\n",
      "Starting bg features - dataset shape: (40101, 130)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (40101, 134)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "54 graphs successfully created\n",
      "Total calculated shock flow is 4 over 3 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (40101, 135)\n",
      "Done!\n",
      "----------SHAPE SANITY CHECK--------\n",
      "Training dataset shape before preprocessing pipeline: (24000, 135)\n",
      "Test dataset shape before preprocessing pipeline: (6000, 135)\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 24000 total, 328 class_1 observations (1.37%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 6000 total, 76 class_1 observations (1.27%) > 0\n",
      "pipeline transform only for test set...\n",
      "Creating fold 1 with X_train of shape (24000, 35), y_train of shape (24000,), X_test of shape (6000, 35) and y_test of shape (6000,)...\n",
      "\n",
      "Preparing fold 2 with 24000 train observations and 6000 test observations, starti=22101...\n",
      "---------Train test for validation fold 2-----------\n",
      "---------Using test df for bond graph features from fold 1 to create TRAIN SET for fold 2-----------\n",
      "Checking train set shape: (40101, 135)\n",
      "---------Adding bond graph features 1 of 3 to TEST SET for fold 2-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 114)...\n",
      "Starting bg features - dataset shape: (46101, 116)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 120)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1489 graphs successfully created\n",
      "Total calculated shock flow is 580601 over 119 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (46101, 121)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TEST SET for fold 2-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 121)...\n",
      "Starting bg features - dataset shape: (46101, 123)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 127)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1337 graphs successfully created\n",
      "Total calculated shock flow is 51830 over 19 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (46101, 128)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TEST SET for fold 2-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 128)...\n",
      "Starting bg features - dataset shape: (46101, 130)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 134)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1308 graphs successfully created\n",
      "Total calculated shock flow is 1716 over 18 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (46101, 135)\n",
      "Done!\n",
      "----------SHAPE SANITY CHECK--------\n",
      "Training dataset shape before preprocessing pipeline: (24000, 135)\n",
      "Test dataset shape before preprocessing pipeline: (6000, 135)\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 24000 total, 336 class_1 observations (1.40%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 6000 total, 169 class_1 observations (2.82%) > 0\n",
      "pipeline transform only for test set...\n",
      "Creating fold 2 with X_train of shape (24000, 35), y_train of shape (24000,), X_test of shape (6000, 35) and y_test of shape (6000,)...\n",
      "\n",
      "---------Saving sequential validation train and test-----------\n",
      "Saving with file name prefix time_2018-04-30_imp_bg__val_24000_6000_ and postfix _190822_99...\n",
      "...done.\n",
      "\n",
      "Decomposing currency column to multiple columns with boolean values...\n",
      "---------Macro train split-----------\n",
      "2201 instruments that are not due yet, dropping...\n",
      "57619 instruments remaining\n",
      "Splitting train and test sets by time, test cutoff: 2018-04-30 00:00:00...\n",
      "  46101(80.0%) train, 11518(20.0%) test\n",
      "---------Adding bond graph features 1 of 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 114)...\n",
      "Starting bg features - dataset shape: (46101, 116)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 120)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1489 graphs successfully created\n",
      "Total calculated shock flow is 580601 over 119 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (46101, 121)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 121)...\n",
      "Starting bg features - dataset shape: (46101, 123)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 127)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n"
     ]
    }
   ],
   "source": [
    "#changing input dataset for the sequential time split\n",
    "inputfilename = '03_instrumentsdf_deg1stats.pkl'\n",
    "df = pd.read_pickle(datafolder+inputfilename)\n",
    "\n",
    "train_window = 24000\n",
    "test_window = 6000\n",
    "\n",
    "bond_graph_settings = [\n",
    "    #impairment settings\n",
    "    {'col_to_calc_effort' : 'purchase_amount',\n",
    "    'effort_col' : 'imp_edge_eff', \n",
    "    'flow_col' : 'imp_edge_flow', \n",
    "    'col_to_calc_flow' : 'total_impairment',\n",
    "     'col_ratio_flow' : 'invoice_amount',\n",
    "    'node_flow_col' : 'imp_node_flow', \n",
    "    'energy_col' : 'imp_energy', \n",
    "    'c_node_eff_col' : 'imp_c_node_eff',\n",
    "    'd_node_flow_col' : 'imp_d_node_flow', \n",
    "    'shock_col' : 'flow_shock_imp1',\n",
    "    'red_coeff' : 10**6},\n",
    "    \n",
    "    #pastdue90 settings\n",
    "    {'col_to_calc_effort' : 'payment_date_mismatch',\n",
    "    'effort_col' : 'p90_edge_eff', \n",
    "    'flow_col' : 'p90_edge_flow', \n",
    "    'col_to_calc_flow' : 'cd_pastdue90_r',\n",
    "     'col_ratio_flow' : None,\n",
    "    'node_flow_col' : 'p90_node_flow', \n",
    "    'energy_col' : 'p90_energy', \n",
    "    'c_node_eff_col' : 'p90_c_node_eff',\n",
    "    'd_node_flow_col' : 'p90_d_node_flow', \n",
    "    'shock_col' : 'flow_shock_p90',\n",
    "    'red_coeff' : 10**4},\n",
    "    \n",
    "    #pastdue180 settings\n",
    "    {'col_to_calc_effort' : 'payment_date_mismatch',\n",
    "    'effort_col' : 'p180_edge_eff', \n",
    "    'flow_col' : 'p180_edge_flow', \n",
    "    'col_to_calc_flow' : 'cd_pastdue180_r',\n",
    "     'col_ratio_flow' : None,\n",
    "    'node_flow_col' : 'p180_node_flow', \n",
    "    'energy_col' : 'p180_energy', \n",
    "    'c_node_eff_col' : 'p180_c_node_eff',\n",
    "    'd_node_flow_col' : 'p180_d_node_flow', \n",
    "    'shock_col' : 'flow_shock_p180',\n",
    "    'red_coeff' : 10**5}\n",
    "]\n",
    "\n",
    "for t in range(len(targets)):\n",
    "    if targets[t]!='is_pastdue180':\n",
    "        tdate = datetime.datetime(2018, 4, 30)\n",
    "          #y_train, X_train, y_test, X_test, if setting validation_prep_only to False comment out these variables\n",
    "        y_train, X_train, y_test, X_test, feature_labels, y_valid_train, X_valid_train, y_valid_test, X_valid_test, folds_idx = preproc_pipeline_timeseq(df, feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                             'invoice_date', 'enriched_time_seq', bond_graph_settings, testdate = tdate,\n",
    "                                                                            train_window=train_window, test_window=test_window,\n",
    "                                                                             save_to_file=True, outputpath=output_path, prefix=pfixes[t],\n",
    "                                                                                   decompose_currency=True, validation_prep_only=False)\n",
    "    else:\n",
    "        tdate = datetime.datetime(2018, 2, 20)\n",
    "         \n",
    "        y_train, X_train, y_test, X_test, feature_labels, y_valid_train, X_valid_train, y_valid_test, X_valid_test, folds_idx = preproc_pipeline_timeseq(df, feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                             'invoice_date', 'enriched_time_seq', bond_graph_settings, testdate = tdate,\n",
    "                                                                             train_window=train_window, test_window=test_window,\n",
    "                                                                                    save_to_file=True, outputpath=output_path, prefix=pfixes[t],\n",
    "                                                                                   decompose_currency=True, validation_prep_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx = []\n",
    "#testx = []\n",
    "#for count, train, test, boh in rolling_window(df.shape[0], 12000, 3000):\n",
    "#    if count==5:\n",
    "#        trainx=train\n",
    "#        testx=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 110)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[testx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
