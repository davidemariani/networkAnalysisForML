{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline 2 - bond graph features models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook starts from the output at step 10 (10_network_featureEng.ipynb) in order to prepare the data to be put into the new bond graph featured models for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime#\n",
    "from scripts_ml.preprocessing_pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data and cleaning unnnecessary instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = \"../data/\"\n",
    "inputfilename = '04_instrumentsdf_bondgraph.pkl'\n",
    "\n",
    "#feature selection\n",
    "feat_str = ['currency']\n",
    "feat_quant = ['has_purchase', 'dd_value_date', 'cd_lent_c', 'cd_repaid_c', 'cd_impaired1_c', 'cd_pastdue90_c', 'cd_trend_a', 'c_lent_c', 'c_repaid_c', 'c_impaired1_c', \n",
    "              'c_pastdue90_c', 'c_trend_a', 'd_repaid_c', 'd_impaired1_c', 'd_pastdue90_c', 'd_trend_a', 'd_we_payment_share', 'flow_shock_imp1', 'imp_c_node_eff', 'imp_energy', 'imp_d_node_flow', \n",
    "              'flow_shock_p90', 'p90_c_node_eff', 'p90_energy', 'p90_d_node_flow', 'flow_shock_p180', 'p180_d_node_flow', 'p180_energy']\n",
    "feat_exp = ['invoice_amount', 'purchase_amount']\n",
    "feat_date = ['invoice_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name_1</th>\n",
       "      <th>debtor_id</th>\n",
       "      <th>debtor_name_1</th>\n",
       "      <th>invoice_number</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>due_date</th>\n",
       "      <th>invoice_amount</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_amount_open</th>\n",
       "      <th>...</th>\n",
       "      <th>p90_c_node_eff</th>\n",
       "      <th>p90_node_flow</th>\n",
       "      <th>p90_energy</th>\n",
       "      <th>flow_shock_p90</th>\n",
       "      <th>p180_edge_flow</th>\n",
       "      <th>p180_d_node_flow</th>\n",
       "      <th>p180_c_node_eff</th>\n",
       "      <th>p180_node_flow</th>\n",
       "      <th>p180_energy</th>\n",
       "      <th>flow_shock_p180</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2744:79/231</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2744</td>\n",
       "      <td>2013-07-23</td>\n",
       "      <td>2013-08-02</td>\n",
       "      <td>913.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861:79/232</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2861</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>2013-08-09</td>\n",
       "      <td>2233.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932:79/233</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2932</td>\n",
       "      <td>2013-08-06</td>\n",
       "      <td>2013-08-16</td>\n",
       "      <td>1370.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239912.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472:489/688</th>\n",
       "      <td>2004009</td>\n",
       "      <td>Orpheus Wyandotte Supply LLC</td>\n",
       "      <td>489</td>\n",
       "      <td>Isfahan SA</td>\n",
       "      <td>1472</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>9195.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>1.665866</td>\n",
       "      <td>366437.206374</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>0.54333</td>\n",
       "      <td>119515.16508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042:512/645</th>\n",
       "      <td>2004009</td>\n",
       "      <td>Orpheus Wyandotte Supply LLC</td>\n",
       "      <td>512</td>\n",
       "      <td>Aldrich Chloe GmbH</td>\n",
       "      <td>2042</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>4594.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>1.665866</td>\n",
       "      <td>366437.206374</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>0.54333</td>\n",
       "      <td>119515.16508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             customer_id               customer_name_1 debtor_id  \\\n",
       "uid                                                                \n",
       "2744:79/231      2004008                 Castillo GmbH        79   \n",
       "2861:79/232      2004008                 Castillo GmbH        79   \n",
       "2932:79/233      2004008                 Castillo GmbH        79   \n",
       "1472:489/688     2004009  Orpheus Wyandotte Supply LLC       489   \n",
       "2042:512/645     2004009  Orpheus Wyandotte Supply LLC       512   \n",
       "\n",
       "                   debtor_name_1 invoice_number invoice_date   due_date  \\\n",
       "uid                                                                       \n",
       "2744:79/231    Sana Hyannis Sarl           2744   2013-07-23 2013-08-02   \n",
       "2861:79/232    Sana Hyannis Sarl           2861   2013-07-30 2013-08-09   \n",
       "2932:79/233    Sana Hyannis Sarl           2932   2013-08-06 2013-08-16   \n",
       "1472:489/688          Isfahan SA           1472   2013-08-13 2013-08-23   \n",
       "2042:512/645  Aldrich Chloe GmbH           2042   2013-08-13 2013-08-23   \n",
       "\n",
       "              invoice_amount  purchase_amount  purchase_amount_open  ...  \\\n",
       "uid                                                                  ...   \n",
       "2744:79/231           913.70              0.0                   0.0  ...   \n",
       "2861:79/232          2233.45              0.0                   0.0  ...   \n",
       "2932:79/233          1370.50              0.0                   0.0  ...   \n",
       "1472:489/688         9195.10              0.0                   0.0  ...   \n",
       "2042:512/645         4594.60              0.0                   0.0  ...   \n",
       "\n",
       "             p90_c_node_eff  p90_node_flow     p90_energy flow_shock_p90  \\\n",
       "uid                                                                        \n",
       "2744:79/231        239912.0       0.000000       0.000000            1.0   \n",
       "2861:79/232        239912.0       0.000000       0.000000            1.0   \n",
       "2932:79/233        239912.0       0.000000       0.000000            1.0   \n",
       "1472:489/688       234247.0       1.665866  366437.206374           36.0   \n",
       "2042:512/645       234247.0       1.665866  366437.206374           36.0   \n",
       "\n",
       "             p180_edge_flow  p180_d_node_flow p180_c_node_eff p180_node_flow  \\\n",
       "uid                                                                            \n",
       "2744:79/231             0.0               0.0        239912.0        0.00000   \n",
       "2861:79/232             0.0               0.0        239912.0        0.00000   \n",
       "2932:79/233             0.0               0.0        239912.0        0.00000   \n",
       "1472:489/688            0.0               0.0        234247.0        0.54333   \n",
       "2042:512/645            0.0               0.0        234247.0        0.54333   \n",
       "\n",
       "               p180_energy flow_shock_p180  \n",
       "uid                                         \n",
       "2744:79/231        0.00000             1.0  \n",
       "2861:79/232        0.00000             1.0  \n",
       "2932:79/233        0.00000             1.0  \n",
       "1472:489/688  119515.16508             1.0  \n",
       "2042:512/645  119515.16508             1.0  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(datafolder+inputfilename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2201 instruments that are not due yet, dropping...\n",
      "57619 instruments remaining\n"
     ]
    }
   ],
   "source": [
    "#drop all instruments that are not due yet, since they can't be labelled\n",
    "print(\"{:} instruments that are not due yet, dropping...\".format(sum(~df.is_due)))\n",
    "df=df.loc[df.is_due, :]\n",
    "print(\"{:} instruments remaining\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['has_impairment1', 'is_pastdue90', 'is_pastdue180']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating preprocessed data for impairment, pastdue90 and pastdue180 credit events - Shuffle mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfixes = ['imp_bg_', 'p90_bg_', 'p180_bg_']\n",
    "output_path = datafolder+\"/preproc_traintest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 46095 for train and 11522 for test sets by shuffling...\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 46095 total, 968 class_1 observations (2.10%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 11522 total, 227 class_1 observations (1.97%) > 0\n",
      "pipeline transform only for test set...\n",
      "Saving with file name prefix shuffle_imp_bg_ and postfix _190721_1655...\n",
      "...done.\n",
      "Sampling 46095 for train and 11522 for test sets by shuffling...\n",
      "Running the pipeline, target feature is is_pastdue90...\n",
      "Train y: 46095 total, 3344 class_1 observations (7.25%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 11522 total, 850 class_1 observations (7.38%) > 0\n",
      "pipeline transform only for test set...\n",
      "Saving with file name prefix shuffle_p90_bg_ and postfix _190721_1655...\n",
      "...done.\n",
      "Sampling 46095 for train and 11522 for test sets by shuffling...\n",
      "Running the pipeline, target feature is is_pastdue180...\n",
      "Train y: 46095 total, 2865 class_1 observations (6.22%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 11522 total, 735 class_1 observations (6.38%) > 0\n",
      "pipeline transform only for test set...\n",
      "Saving with file name prefix shuffle_p180_bg_ and postfix _190721_1655...\n",
      "...done.\n"
     ]
    }
   ],
   "source": [
    "for t in range(len(targets)):\n",
    "    y_train, X_train, y_test, X_test, feature_labels = preprocessing_pipeline(df, feat_str, feat_quant, feat_exp, feat_date, targets[t], 'invoice_date', \n",
    "                                                                              'enriched_shuffle', trainsize = int(df.shape[0]*.80), testsize = int(df.shape[0]*.20)-1,\n",
    "                                                                         save_to_file=True, outputpath=output_path, prefix=pfixes[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating preprocessed data for impairment, pastdue90 and pastdue180 credit events - Timewise mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train and test sets by time, test cutoff: 2018-04-30 00:00:00...\n",
      "  46101(80.0%) train, 11518(20.0%) test\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 46101 total, 710 class_1 observations (1.54%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 11518 total, 485 class_1 observations (4.21%) > 0\n",
      "pipeline transform only for test set...\n",
      "Saving with file name prefix time_2018-04-30_imp_bg_ and postfix _190721_170...\n",
      "...done.\n",
      "Splitting train and test sets by time, test cutoff: 2018-04-30 00:00:00...\n",
      "  46101(80.0%) train, 11518(20.0%) test\n",
      "Running the pipeline, target feature is is_pastdue90...\n",
      "Train y: 46101 total, 3973 class_1 observations (8.62%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 11518 total, 222 class_1 observations (1.93%) > 0\n",
      "pipeline transform only for test set...\n",
      "Saving with file name prefix time_2018-04-30_p90_bg_ and postfix _190721_170...\n",
      "...done.\n",
      "Splitting train and test sets by time, test cutoff: 2018-02-20 00:00:00...\n",
      "  42079(73.0%) train, 15540(27.0%) test\n",
      "Running the pipeline, target feature is is_pastdue180...\n",
      "Train y: 42079 total, 3547 class_1 observations (8.43%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 15540 total, 54 class_1 observations (0.35%) > 0\n",
      "pipeline transform only for test set...\n",
      "Saving with file name prefix time_2018-02-20_p180_bg_ and postfix _190721_170...\n",
      "...done.\n"
     ]
    }
   ],
   "source": [
    "for t in range(len(targets)):\n",
    "    if t!=2:\n",
    "        tdate = datetime.datetime(2018, 4, 30)\n",
    "        y_train, X_train, y_test, X_test, feature_labels = preprocessing_pipeline(df, feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                             'invoice_date', 'enriched_time', timewise=True, testdate = tdate,\n",
    "                                                                             save_to_file=True, outputpath=output_path, prefix=pfixes[t])\n",
    "    else:\n",
    "        tdate = datetime.datetime(2018, 2, 20)\n",
    "        y_train, X_train, y_test, X_test, feature_labels = preprocessing_pipeline(df, feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                             'invoice_date', 'enriched_time', timewise=True, testdate = tdate,\n",
    "                                                                             save_to_file=True, outputpath=output_path, prefix=pfixes[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating preprocessed data for impairment, pastdue90 and pastdue180 credit events - Sequential Timewise mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name_1</th>\n",
       "      <th>debtor_id</th>\n",
       "      <th>debtor_name_1</th>\n",
       "      <th>invoice_number</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>due_date</th>\n",
       "      <th>invoice_amount</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_amount_open</th>\n",
       "      <th>...</th>\n",
       "      <th>c_pastdue90_c</th>\n",
       "      <th>c_pastdue180_c</th>\n",
       "      <th>c_trend_a</th>\n",
       "      <th>c_we_payment_share</th>\n",
       "      <th>c_pd_mismatch_mean</th>\n",
       "      <th>c_pd_mismatch_std</th>\n",
       "      <th>c_repaid_r</th>\n",
       "      <th>c_impaired1_r</th>\n",
       "      <th>c_pastdue90_r</th>\n",
       "      <th>c_pastdue180_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2744:79/231</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2744</td>\n",
       "      <td>2013-07-23</td>\n",
       "      <td>2013-08-02</td>\n",
       "      <td>913.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861:79/232</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2861</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>2013-08-09</td>\n",
       "      <td>2233.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932:79/233</th>\n",
       "      <td>2004008</td>\n",
       "      <td>Castillo GmbH</td>\n",
       "      <td>79</td>\n",
       "      <td>Sana Hyannis Sarl</td>\n",
       "      <td>2932</td>\n",
       "      <td>2013-08-06</td>\n",
       "      <td>2013-08-16</td>\n",
       "      <td>1370.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.185198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472:489/688</th>\n",
       "      <td>2004009</td>\n",
       "      <td>Orpheus Wyandotte Supply LLC</td>\n",
       "      <td>489</td>\n",
       "      <td>Isfahan SA</td>\n",
       "      <td>1472</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>9195.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042:512/645</th>\n",
       "      <td>2004009</td>\n",
       "      <td>Orpheus Wyandotte Supply LLC</td>\n",
       "      <td>512</td>\n",
       "      <td>Aldrich Chloe GmbH</td>\n",
       "      <td>2042</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>4594.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             customer_id               customer_name_1 debtor_id  \\\n",
       "uid                                                                \n",
       "2744:79/231      2004008                 Castillo GmbH        79   \n",
       "2861:79/232      2004008                 Castillo GmbH        79   \n",
       "2932:79/233      2004008                 Castillo GmbH        79   \n",
       "1472:489/688     2004009  Orpheus Wyandotte Supply LLC       489   \n",
       "2042:512/645     2004009  Orpheus Wyandotte Supply LLC       512   \n",
       "\n",
       "                   debtor_name_1 invoice_number invoice_date   due_date  \\\n",
       "uid                                                                       \n",
       "2744:79/231    Sana Hyannis Sarl           2744   2013-07-23 2013-08-02   \n",
       "2861:79/232    Sana Hyannis Sarl           2861   2013-07-30 2013-08-09   \n",
       "2932:79/233    Sana Hyannis Sarl           2932   2013-08-06 2013-08-16   \n",
       "1472:489/688          Isfahan SA           1472   2013-08-13 2013-08-23   \n",
       "2042:512/645  Aldrich Chloe GmbH           2042   2013-08-13 2013-08-23   \n",
       "\n",
       "              invoice_amount  purchase_amount  purchase_amount_open  ...  \\\n",
       "uid                                                                  ...   \n",
       "2744:79/231           913.70              0.0                   0.0  ...   \n",
       "2861:79/232          2233.45              0.0                   0.0  ...   \n",
       "2932:79/233          1370.50              0.0                   0.0  ...   \n",
       "1472:489/688         9195.10              0.0                   0.0  ...   \n",
       "2042:512/645         4594.60              0.0                   0.0  ...   \n",
       "\n",
       "             c_pastdue90_c  c_pastdue180_c c_trend_a c_we_payment_share  \\\n",
       "uid                                                                       \n",
       "2744:79/231            0.0             0.0  0.000000                NaN   \n",
       "2861:79/232            0.0             0.0  0.000000                NaN   \n",
       "2932:79/233            0.0             0.0  7.185198                NaN   \n",
       "1472:489/688           0.0             0.0  0.000000                NaN   \n",
       "2042:512/645           0.0             0.0  0.000000                NaN   \n",
       "\n",
       "             c_pd_mismatch_mean  c_pd_mismatch_std c_repaid_r c_impaired1_r  \\\n",
       "uid                                                                           \n",
       "2744:79/231                 NaN                NaN        NaN           NaN   \n",
       "2861:79/232                 NaN                NaN        0.0           0.0   \n",
       "2932:79/233                 NaN                NaN        0.0           0.0   \n",
       "1472:489/688                NaN                NaN        NaN           NaN   \n",
       "2042:512/645                NaN                NaN        0.0           0.0   \n",
       "\n",
       "             c_pastdue90_r c_pastdue180_r  \n",
       "uid                                        \n",
       "2744:79/231            NaN            NaN  \n",
       "2861:79/232            0.0            0.0  \n",
       "2932:79/233            0.0            0.0  \n",
       "1472:489/688           NaN            NaN  \n",
       "2042:512/645           0.0            0.0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputfilename = '03_instrumentsdf_deg1stats.pkl'\n",
    "df = pd.read_pickle(datafolder+inputfilename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Macro train split-----------\n",
      "Dropping 2201 instruments that are not due...\n",
      "Splitting train and test sets by time, test cutoff: 2018-04-30 00:00:00...\n",
      "  46101(80.0%) train, 11518(20.0%) test\n",
      "---------Adding bond graph features 1 of 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 110)...\n",
      "Starting bg features - dataset shape: (46101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1477 graphs successfully created\n",
      "Total calculated shock flow is 58053263 over 136 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (46101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 117)...\n",
      "Starting bg features - dataset shape: (46101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1325 graphs successfully created\n",
      "Total calculated shock flow is 291 over 114 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (46101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (46101, 124)...\n",
      "Starting bg features - dataset shape: (46101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (46101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1296 graphs successfully created\n",
      "Total calculated shock flow is 285 over 111 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (46101, 131)\n",
      "Done!\n",
      "---------Macro test split-----------\n",
      "Dropping 2201 instruments that are not due...\n",
      "Splitting train and test sets by time, test cutoff: 2018-04-30 00:00:00...\n",
      "  46101(80.0%) train, 11518(20.0%) test\n",
      "---------Pipeline application-----------\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 46101 total, 710 class_1 observations (1.54%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 11518 total, 485 class_1 observations (4.21%) > 0\n",
      "pipeline transform only for test set...\n",
      "---------Macro train-test saving-----------\n",
      "Saving with file name prefix time_2018-04-30_imp_bg_ and postfix _190812_651...\n",
      "...done.\n",
      "---------Sequential validation splits-----------\n",
      "Preparing fold 0 with start at 4101, 13101 train observations and 3000 test observations...\n",
      "---------Train test for validation fold 0-----------\n",
      "---------Adding bond graph features 1 of 3 to TRAIN SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (13101, 110)...\n",
      "Starting bg features - dataset shape: (13101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (13101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "169 graphs successfully created\n",
      "Total calculated shock flow is 240999 over 20 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (13101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 1 of 3 to TEST SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (16101, 110)...\n",
      "Starting bg features - dataset shape: (16101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (16101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "266 graphs successfully created\n",
      "Total calculated shock flow is 305103 over 22 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (16101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TRAIN SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (13101, 117)...\n",
      "Starting bg features - dataset shape: (13101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (13101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1 graphs successfully created\n",
      "Total calculated shock flow is 0 over 0 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (13101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TEST SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (16101, 117)...\n",
      "Starting bg features - dataset shape: (16101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (16101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "12 graphs successfully created\n",
      "Total calculated shock flow is 22 over 11 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (16101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TRAIN SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (13101, 124)...\n",
      "Starting bg features - dataset shape: (13101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (13101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1 graphs successfully created\n",
      "Total calculated shock flow is 0 over 0 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (13101, 131)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TEST SET for fold 0-----------\n",
      "Calculating effort and flow for starting dataset with shape (16101, 124)...\n",
      "Starting bg features - dataset shape: (16101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (16101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1 graphs successfully created\n",
      "Total calculated shock flow is 0 over 0 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (16101, 131)\n",
      "Done!\n",
      "Training dataset shape before preprocessing pipeline: (13101, 131)\n",
      "Testing dataset shape before preprocessing pipeline: (3000, 131)\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 13101 total, 160 class_1 observations (1.22%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 3000 total, 45 class_1 observations (1.50%) > 0\n",
      "pipeline transform only for test set...\n",
      "Creating first fold with X_train of shape (13101, 35), y_train of shape (13101,), X_test of shape (3000, 35) and y_test of shape (3000,)...\n",
      "\n",
      "Preparing fold 1 with start at 7101, 12000 train observations and 3000 test observations...\n",
      "---------Train test for validation fold 1-----------\n",
      "---------Adding bond graph features 1 of 3 to TRAIN SET for fold 1-----------\n",
      "Calculating effort and flow for starting dataset with shape (16101, 110)...\n",
      "Starting bg features - dataset shape: (16101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (16101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "266 graphs successfully created\n",
      "Total calculated shock flow is 305103 over 22 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (16101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 1 of 3 to TEST SET for fold 1-----------\n",
      "Calculating effort and flow for starting dataset with shape (19101, 110)...\n",
      "Starting bg features - dataset shape: (19101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (19101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "581 graphs successfully created\n",
      "Total calculated shock flow is 349260 over 24 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (19101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TRAIN SET for fold 1-----------\n",
      "Calculating effort and flow for starting dataset with shape (16101, 117)...\n",
      "Starting bg features - dataset shape: (16101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (16101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "12 graphs successfully created\n",
      "Total calculated shock flow is 22 over 11 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (16101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TEST SET for fold 1-----------\n",
      "Calculating effort and flow for starting dataset with shape (19101, 117)...\n",
      "Starting bg features - dataset shape: (19101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (19101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "15 graphs successfully created\n",
      "Total calculated shock flow is 24 over 12 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (19101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TRAIN SET for fold 1-----------\n",
      "Calculating effort and flow for starting dataset with shape (16101, 124)...\n",
      "Starting bg features - dataset shape: (16101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (16101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1 graphs successfully created\n",
      "Total calculated shock flow is 0 over 0 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (16101, 131)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TEST SET for fold 1-----------\n",
      "Calculating effort and flow for starting dataset with shape (19101, 124)...\n",
      "Starting bg features - dataset shape: (19101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (19101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "3 graphs successfully created\n",
      "Total calculated shock flow is 0 over 0 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (19101, 131)\n",
      "Done!\n",
      "Training dataset shape before preprocessing pipeline: (12000, 131)\n",
      "Testing dataset shape before preprocessing pipeline: (3000, 131)\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 12000 total, 155 class_1 observations (1.29%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 3000 total, 43 class_1 observations (1.43%) > 0\n",
      "pipeline transform only for test set...\n",
      "Creating fold 1 with X_train of shape (12000, 35), y_train of shape (12000,), X_test of shape (3000, 35) and y_test of shape (3000,)...\n",
      "\n",
      "Preparing fold 2 with start at 10101, 12000 train observations and 3000 test observations...\n",
      "---------Train test for validation fold 2-----------\n",
      "---------Adding bond graph features 1 of 3 to TRAIN SET for fold 2-----------\n",
      "Calculating effort and flow for starting dataset with shape (19101, 110)...\n",
      "Starting bg features - dataset shape: (19101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (19101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "581 graphs successfully created\n",
      "Total calculated shock flow is 349260 over 24 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (19101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 1 of 3 to TEST SET for fold 2-----------\n",
      "Calculating effort and flow for starting dataset with shape (22101, 110)...\n",
      "Starting bg features - dataset shape: (22101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (22101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "598 graphs successfully created\n",
      "Total calculated shock flow is 4894 over 22 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (22101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TRAIN SET for fold 2-----------\n",
      "Calculating effort and flow for starting dataset with shape (19101, 117)...\n",
      "Starting bg features - dataset shape: (19101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (19101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "15 graphs successfully created\n",
      "Total calculated shock flow is 24 over 12 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (19101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TEST SET for fold 2-----------\n",
      "Calculating effort and flow for starting dataset with shape (22101, 117)...\n",
      "Starting bg features - dataset shape: (22101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (22101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "570 graphs successfully created\n",
      "Total calculated shock flow is 26 over 13 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (22101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TRAIN SET for fold 2-----------\n",
      "Calculating effort and flow for starting dataset with shape (19101, 124)...\n",
      "Starting bg features - dataset shape: (19101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (19101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "3 graphs successfully created\n",
      "Total calculated shock flow is 0 over 0 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (19101, 131)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TEST SET for fold 2-----------\n",
      "Calculating effort and flow for starting dataset with shape (22101, 124)...\n",
      "Starting bg features - dataset shape: (22101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (22101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "2 graphs successfully created\n",
      "Total calculated shock flow is 0 over 0 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (22101, 131)\n",
      "Done!\n",
      "Training dataset shape before preprocessing pipeline: (12000, 131)\n",
      "Testing dataset shape before preprocessing pipeline: (3000, 131)\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 12000 total, 142 class_1 observations (1.18%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 3000 total, 55 class_1 observations (1.83%) > 0\n",
      "pipeline transform only for test set...\n",
      "Creating fold 2 with X_train of shape (12000, 35), y_train of shape (12000,), X_test of shape (3000, 35) and y_test of shape (3000,)...\n",
      "\n",
      "Preparing fold 3 with start at 13101, 12000 train observations and 3000 test observations...\n",
      "---------Train test for validation fold 3-----------\n",
      "---------Adding bond graph features 1 of 3 to TRAIN SET for fold 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (22101, 110)...\n",
      "Starting bg features - dataset shape: (22101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (22101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "598 graphs successfully created\n",
      "Total calculated shock flow is 4894 over 22 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (22101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 1 of 3 to TEST SET for fold 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (25101, 110)...\n",
      "Starting bg features - dataset shape: (25101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (25101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1014 graphs successfully created\n",
      "Total calculated shock flow is 80994 over 35 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (25101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TRAIN SET for fold 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (22101, 117)...\n",
      "Starting bg features - dataset shape: (22101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (22101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "570 graphs successfully created\n",
      "Total calculated shock flow is 26 over 13 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (22101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TEST SET for fold 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (25101, 117)...\n",
      "Starting bg features - dataset shape: (25101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (25101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "938 graphs successfully created\n",
      "Total calculated shock flow is 28 over 15 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (25101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TRAIN SET for fold 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (22101, 124)...\n",
      "Starting bg features - dataset shape: (22101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (22101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "2 graphs successfully created\n",
      "Total calculated shock flow is 0 over 0 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (22101, 131)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TEST SET for fold 3-----------\n",
      "Calculating effort and flow for starting dataset with shape (25101, 124)...\n",
      "Starting bg features - dataset shape: (25101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (25101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "4 graphs successfully created\n",
      "Total calculated shock flow is 2 over 2 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (25101, 131)\n",
      "Done!\n",
      "Training dataset shape before preprocessing pipeline: (12000, 131)\n",
      "Testing dataset shape before preprocessing pipeline: (3000, 131)\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 12000 total, 166 class_1 observations (1.38%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 3000 total, 48 class_1 observations (1.60%) > 0\n",
      "pipeline transform only for test set...\n",
      "Creating fold 3 with X_train of shape (12000, 35), y_train of shape (12000,), X_test of shape (3000, 35) and y_test of shape (3000,)...\n",
      "\n",
      "Preparing fold 4 with start at 16101, 12000 train observations and 3000 test observations...\n",
      "---------Train test for validation fold 4-----------\n",
      "---------Adding bond graph features 1 of 3 to TRAIN SET for fold 4-----------\n",
      "Calculating effort and flow for starting dataset with shape (25101, 110)...\n",
      "Starting bg features - dataset shape: (25101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (25101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1014 graphs successfully created\n",
      "Total calculated shock flow is 80994 over 35 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (25101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 1 of 3 to TEST SET for fold 4-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 110)...\n",
      "Starting bg features - dataset shape: (28101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1102 graphs successfully created\n",
      "Total calculated shock flow is 885354 over 106 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TRAIN SET for fold 4-----------\n",
      "Calculating effort and flow for starting dataset with shape (25101, 117)...\n",
      "Starting bg features - dataset shape: (25101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (25101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "938 graphs successfully created\n",
      "Total calculated shock flow is 28 over 15 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (25101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TEST SET for fold 4-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 117)...\n",
      "Starting bg features - dataset shape: (28101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "994 graphs successfully created\n",
      "Total calculated shock flow is 229 over 82 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TRAIN SET for fold 4-----------\n",
      "Calculating effort and flow for starting dataset with shape (25101, 124)...\n",
      "Starting bg features - dataset shape: (25101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (25101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "4 graphs successfully created\n",
      "Total calculated shock flow is 2 over 2 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (25101, 131)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TEST SET for fold 4-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 124)...\n",
      "Starting bg features - dataset shape: (28101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "4 graphs successfully created\n",
      "Total calculated shock flow is 2 over 2 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 131)\n",
      "Done!\n",
      "Training dataset shape before preprocessing pipeline: (12000, 131)\n",
      "Testing dataset shape before preprocessing pipeline: (3000, 131)\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 12000 total, 191 class_1 observations (1.59%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 3000 total, 44 class_1 observations (1.47%) > 0\n",
      "pipeline transform only for test set...\n",
      "Creating fold 4 with X_train of shape (12000, 35), y_train of shape (12000,), X_test of shape (3000, 35) and y_test of shape (3000,)...\n",
      "\n",
      "Preparing fold 5 with start at 19101, 12000 train observations and 3000 test observations...\n",
      "---------Train test for validation fold 5-----------\n",
      "---------Adding bond graph features 1 of 3 to TRAIN SET for fold 5-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 110)...\n",
      "Starting bg features - dataset shape: (28101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1102 graphs successfully created\n",
      "Total calculated shock flow is 885354 over 106 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 1 of 3 to TEST SET for fold 5-----------\n",
      "Calculating effort and flow for starting dataset with shape (31101, 110)...\n",
      "Starting bg features - dataset shape: (31101, 112)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (31101, 116)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1193 graphs successfully created\n",
      "Total calculated shock flow is 2096011 over 114 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (31101, 117)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TRAIN SET for fold 5-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 117)...\n",
      "Starting bg features - dataset shape: (28101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "994 graphs successfully created\n",
      "Total calculated shock flow is 229 over 82 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 2 of 3 to TEST SET for fold 5-----------\n",
      "Calculating effort and flow for starting dataset with shape (31101, 117)...\n",
      "Starting bg features - dataset shape: (31101, 119)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (31101, 123)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "1061 graphs successfully created\n",
      "Total calculated shock flow is 248 over 89 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (31101, 124)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TRAIN SET for fold 5-----------\n",
      "Calculating effort and flow for starting dataset with shape (28101, 124)...\n",
      "Starting bg features - dataset shape: (28101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (28101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "4 graphs successfully created\n",
      "Total calculated shock flow is 2 over 2 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (28101, 131)\n",
      "Done!\n",
      "---------Adding bond graph features 3 of 3 to TEST SET for fold 5-----------\n",
      "Calculating effort and flow for starting dataset with shape (31101, 124)...\n",
      "Starting bg features - dataset shape: (31101, 126)\n",
      "Creating the undirected graph of the whole dataset network...\n",
      "Adding effort and flow feature to the dataset...\n",
      "Dataset shape after effort and flow features: (31101, 130)\n",
      "Isolating components and creating directed graphs...\n",
      "Looking for hybrid nodes...\n",
      "Modelling the flow...\n",
      "Creating flow graphs...\n",
      "4 graphs successfully created\n",
      "Total calculated shock flow is 2 over 2 graphs with positive flow value\n",
      "Overlapping the flows...\n",
      "Adding shock-propagation features...\n",
      "Final dataset shape: (31101, 131)\n",
      "Done!\n",
      "Training dataset shape before preprocessing pipeline: (12000, 131)\n",
      "Testing dataset shape before preprocessing pipeline: (3000, 131)\n",
      "Running the pipeline, target feature is has_impairment1...\n",
      "Train y: 12000 total, 190 class_1 observations (1.58%) > 0\n",
      "pipeline fit_transform for train set...\n",
      "Test y: 3000 total, 27 class_1 observations (0.90%) > 0\n",
      "pipeline transform only for test set...\n",
      "Creating fold 5 with X_train of shape (12000, 34), y_train of shape (12000,), X_test of shape (3000, 34) and y_test of shape (3000,)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-50b4a5e6d5f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m                                                                              \u001b[1;34m'invoice_date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'enriched_time_seq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbond_graph_settings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                                                                             \u001b[0mtrain_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                                                                              save_to_file=True, outputpath=output_path, prefix=pfixes[t])\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mtdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\University\\MscDataScience_Birkbeck\\thesis_project\\code\\scripts_ml\\preprocessing_pipeline.py\u001b[0m in \u001b[0;36mpreproc_pipeline_timeseq\u001b[1;34m(df, feat_str, feat_quant, feat_exp, feat_date, target_feature, testset_control_feature, experimentname, bg_settings_dicts, testdate, train_window, test_window, whole_network_with_bg_file_path, save_to_file, outputpath, prefix)\u001b[0m\n\u001b[0;32m    425\u001b[0m             print(\"Creating fold {} with X_train of shape {}, y_train of shape {}, X_test of shape {} and y_test of shape {}...\".format(count, X_train_fold.shape, y_train_fold.shape, \n\u001b[0;32m    426\u001b[0m                                                                                                                                            X_test_fold.shape, y_test_fold.shape))\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mX_valid_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_valid_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_fold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m             \u001b[0my_valid_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_valid_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_fold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[0mX_valid_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_valid_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_fold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "bond_graph_settings = [\n",
    "    {'col_to_calc_effort' : 'purchase_amount',\n",
    "    'effort_col' : 'imp_edge_eff', \n",
    "    'flow_col' : 'imp_edge_flow', \n",
    "    'col_to_calc_flow' : 'total_impairment',\n",
    "     'col_ratio_flow' : 'invoice_amount',\n",
    "    'node_flow_col' : 'imp_node_flow', \n",
    "    'energy_col' : 'imp_energy', \n",
    "    'c_node_eff_col' : 'imp_c_node_eff',\n",
    "    'd_node_flow_col' : 'imp_d_node_flow', \n",
    "    'shock_col' : 'flow_shock_imp1',\n",
    "    'red_coeff' : 10**4},\n",
    "    \n",
    "    {'col_to_calc_effort' : 'payment_date_mismatch',\n",
    "    'effort_col' : 'p90_edge_eff', \n",
    "    'flow_col' : 'p90_edge_flow', \n",
    "    'col_to_calc_flow' : 'cd_pastdue90_r',\n",
    "     'col_ratio_flow' : 'invoice_amount',\n",
    "    'node_flow_col' : 'p90_node_flow', \n",
    "    'energy_col' : 'p90_energy', \n",
    "    'c_node_eff_col' : 'p90_c_node_eff',\n",
    "    'd_node_flow_col' : 'p90_d_node_flow', \n",
    "    'shock_col' : 'flow_shock_p90',\n",
    "    'red_coeff' : 10**4},\n",
    "    \n",
    "    {'col_to_calc_effort' : 'payment_date_mismatch',\n",
    "    'effort_col' : 'p180_edge_eff', \n",
    "    'flow_col' : 'p180_edge_flow', \n",
    "    'col_to_calc_flow' : 'cd_pastdue180_r',\n",
    "     'col_ratio_flow' : 'invoice_amount',\n",
    "    'node_flow_col' : 'p180_node_flow', \n",
    "    'energy_col' : 'p180_energy', \n",
    "    'c_node_eff_col' : 'p180_c_node_eff',\n",
    "    'd_node_flow_col' : 'p180_d_node_flow', \n",
    "    'shock_col' : 'flow_shock_p180',\n",
    "    'red_coeff' : 10**4}\n",
    "]\n",
    "\n",
    "for t in range(len(targets)):\n",
    "    if t!=2:\n",
    "        tdate = datetime.datetime(2018, 4, 30)\n",
    "        y_train, X_train, y_test, X_test, feature_labels = preproc_pipeline_timeseq(df, feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                             'invoice_date', 'enriched_time_seq', bond_graph_settings, testdate = tdate,\n",
    "                                                                            train_window=12000, test_window=3000,\n",
    "                                                                             save_to_file=True, outputpath=output_path, prefix=pfixes[t])\n",
    "    else:\n",
    "        tdate = datetime.datetime(2018, 2, 20)\n",
    "        y_train, X_train, y_test, X_test, feature_labels = preproc_pipeline_timeseq(df, feat_str, feat_quant, feat_exp, feat_date, targets[t],\n",
    "                                                                             'invoice_date', 'enriched_time_seq', bond_graph_settings, testdate = tdate,\n",
    "                                                                             train_window=12000, test_window=3000,\n",
    "                                                                                    save_to_file=True, outputpath=output_path, prefix=pfixes[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing fold 0 with start at 5820, 14820 train observations and 3000 test observations...\n",
      "Preparing fold 1 with start at 8820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 2 with start at 11820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 3 with start at 14820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 4 with start at 17820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 5 with start at 20820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 6 with start at 23820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 7 with start at 26820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 8 with start at 29820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 9 with start at 32820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 10 with start at 35820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 11 with start at 38820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 12 with start at 41820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 13 with start at 44820, 12000 train observations and 3000 test observations...\n",
      "Preparing fold 14 with start at 47820, 12000 train observations and 3000 test observations...\n"
     ]
    }
   ],
   "source": [
    "#trainx = []\n",
    "#testx = []\n",
    "#for count, train, test, boh in rolling_window(df.shape[0], 12000, 3000):\n",
    "#    if count==5:\n",
    "#        trainx=train\n",
    "#        testx=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 110)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[testx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
